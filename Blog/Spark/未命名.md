
[[Picture/e2f30120fd577a7a8efea3b4b5c73f81_MD5.png|Open: Pasted image 20230925144818.png]]
![[Picture/e2f30120fd577a7a8efea3b4b5c73f81_MD5.png]]
[[Picture/c6a47db96a8338bf26f2e945a9722bdf_MD5.png|Open: Pasted image 20230925144827.png]]
![[Picture/c6a47db96a8338bf26f2e945a9722bdf_MD5.png]]


实现流程：
新增一个监听器（UIMetaLoggingListener），监听相关的事件（stageEnd，JobEnd）。每次写操作是批量的写，将上一阶段的UIMetaStore的信息完整地持久化。





[[Picture/3cb89a0f515b8d8e9c67577867d0ac2b_MD5.png|Open: Pasted image 20230925144836.png]]
![[Picture/3cb89a0f515b8d8e9c67577867d0ac2b_MD5.png]]











现在SHS实现流程图


## UIMetaStore存储信息：
### AppStatusStore （存储所有需要的信息）
	org.apache.spark.status.JobDataWrapper:Job相关信息报错
	    val info: JobData,
	    val skippedStages: Set[Int],
	    val sqlExecutionId: Option[Long]

	org.apache.spark.status.ExecutorStageSummaryWrapper
        val stageId: Int,
        val stageAttemptId: Int,
    	val executorId: String,
    	val info: ExecutorStageSummary

	org.apache.spark.status.ApplicationInfoWrapper
		val info: ApplicationInfo

	org.apache.spark.status.PoolData
		val name: String,
    	        val stageIds: Set[Int]

	org.apache.spark.status.ExecutorSummaryWrapper
		val info: ExecutorSummary

	org.apache.spark.status.StageDataWrapper
		val info: StageData,
    		val jobIds: Set[Int],
    		@JsonDeserialize(contentAs = classOf[JLong])
    		val locality: Map[String, Long]

	org.apache.spark.status.AppSummary
		val numCompletedJobs: Int,
    	        	val numCompletedStages: Int

	org.apache.spark.status.RDDOperationGraphWrapper
		val stageId: Int,
    		val edges: collection.Seq[RDDOperationEdge],
    		val outgoingEdges: collection.Seq[RDDOperationEdge],
    		val incomingEdges: collection.Seq[RDDOperationEdge],
    		val rootCluster: RDDOperationClusterWrapper


	org.apache.spark.status.TaskDataWrapper
		val taskId: JLong,
		val index: Int,
		val attempt: Int,
		val partitionId: Int = -1,
	    	val launchTime: Long,
	    	val resultFetchStart: Long,
	    	val duration: Long,
	    	val executorId: String,
	    	val host: String,
	    	val status: String,
	    	val taskLocality: String,
	    	val speculative: Boolean,
	    	val accumulatorUpdates: collection.Seq[AccumulableInfo],
	    	val errorMessage: Option[String],
	    	val hasMetrics: Boolean,
	    	val executorDeserializeTime: Long,
	    	val executorDeserializeCpuTime: Long,
	    	val executorRunTime: Long,
	    	val executorCpuTime: Long,
	    	val resultSize: Long,
	    	val jvmGcTime: Long,
	    	val resultSerializationTime: Long,
	    	val memoryBytesSpilled: Long,
	    	val diskBytesSpilled: Long,
	    	val peakExecutionMemory: Long,
	    	val inputBytesRead: Long,
	    	val inputRecordsRead: Long,
	    	val outputBytesWritten: Long,
	    	val outputRecordsWritten: Long,
	    	val shuffleRemoteBlocksFetched: Long,
	    	val shuffleLocalBlocksFetched: Long,
	    	val shuffleFetchWaitTime: Long,
	    	val shuffleRemoteBytesRead: Long,
	    	val shuffleRemoteBytesReadToDisk: Long,
	    	val shuffleLocalBytesRead: Long,
	    	val shuffleRecordsRead: Long,          -- 值
	    	val shuffleCorruptMergedBlockChunks: Long,
	    	val shuffleMergedFetchFallbackCount: Long,
	    	val shuffleMergedRemoteBlocksFetched: Long,
	    	val shuffleMergedLocalBlocksFetched: Long,
	    	val shuffleMergedRemoteChunksFetched: Long,
	    	val shuffleMergedLocalChunksFetched: Long,
	    	val shuffleMergedRemoteBytesRead: Long,
	    	val shuffleMergedLocalBytesRead: Long,
	    	val shuffleRemoteReqsDuration: Long,
	    	val shuffleMergedRemoteReqDuration: Long,
	    	val shuffleBytesWritten: Long,
	    	val shuffleWriteTime: Long,
	    	val shuffleRecordsWritten: Long,        -- 值
	    	val stageId: Int,
	    	val stageAttemptId: Int

	org.apache.spark.status.ApplicationEnvironmentInfoWrapper
		val info: ApplicationEnvironmentInfo

### SQLAppStatusStore
	org.apache.spark.sql.execution.ui.SQLExecutionUIData
		val executionId: Long,
	    	val rootExecutionId: Long,
	    	val description: String,
	    	val details: String,
	    	val physicalPlanDescription: String,
	    	val modifiedConfigs: Map[String, String],
	    	val metrics: collection.Seq[SQLPlanMetric],
	    	val submissionTime: Long,
	    	val completionTime: Option[Date],
	    	val errorMessage: Option[String],
	    	val jobs: Map[Int, JobExecutionStatus],
	    	val stages: Set[Int],
	    	val metricValues: Map[Long, String]

	org.apache.spark.sql.execution.ui.SparkPlanGraphWrapper
		val executionId: Long,
	    	val nodes: collection.Seq[SparkPlanGraphNodeWrapper],
	    	val edges: collection.Seq[SparkPlanGraphEdge]


# 类的介绍：
AppStatusStore:从store中获取数据，处理后返回给Spark UI体系中提供的各种UI Tab，进行数据展示

## 处理的事件类型：
	SparkListenerApplicationStart
	SparkListenerApplicationEnd
	SparkListenerLogStart
	SparkListenerEnvironmentUpdate

## 结构对比


[[Picture/fd8b096c3c8091d7fb3aa16802866185_MD5.png|Open: Pasted image 20230925144856.png]]
![[Picture/fd8b096c3c8091d7fb3aa16802866185_MD5.png]]



## 实现思路：
### 思路一：
	存储AppStatusStore对象，将AppStatusStore的数据序列化，直接进行存储。在实现新的系统，从AppStatusStore对象中之间获取相应的数据，利用现有的页面构造功能，构造出相应的请求页面。
具体做法：
	Spark Driver在运行过程中本身就会通过AppStatusListener监听事件并将作业运行的状态数据存储到ElementTrackingStore（数据存储在基于内存的KVStore），以便跟踪作业的运行情况。History Server回放Event log其实是重复这一过程。如果在作业运行过程中直接将状态数据持久化到FileSystem，这样就不用再存储大量Event了。
	UIMetaListener创建一个ElementTrackingStore实例，用作Temp Store。通过一个线程定期遍历Original ElementTrackingStore中的数据，对于每一条数据，检查Temp Store是否存在相同key的旧数据。若不存在，就将数据写入Backup Store，然后再写出到UI Meta文件；若存在则计算两条数据的MD5并进行对比，若不一致，说明数据已更新，就将新的数据写入Backup Store，然后再写出到UI Meta文件。
	Temp Store用于临时存储可能还会发生变化的数据，而对于已经完成的Job/Stage/Task，其状态数据不会再变，而且已经持久化到UI Meta文件，因此需要及时将其从Temp Store清理掉，避免占用太多内存资源。UIMetaListener通过两种方式触发清理，一种是监听到TaskStart/TaskEnd事件时触发，一种是往Temp Store写入数据时触发。	（清理相关的数据：一是监听到相关的结束事件，）

具体做法二：
	在AppStatusListener中，在处理onApplicationEnd事件时，将现有的KVStore当中的数据进行序列化出来，然后存放在一个文件当中。当后期History启动的时候，通过文件来序列化出所有的KVStore数据。缺点：实时的数据无法进行展示，意味着history在显示时，只能显示完成的作业。二是只要原KVStore数据库写入一条就同步到文件中，当文件中的数据更新时，加载到相应的History服务KvStore中。对于SQL中的SQLAppStatusListener进行同样的处理。









### 思路二：
	Spark中有相应的ApplicationCacheOperations类，观察是否可以直接序列化这个对象，然后直接进行构造。
	ApplicationCache(缓存application UIs)
	ApplicationCacheOperationsI(缓存event的API)



## 字节文章重点语句记录
1：无论运行中的 Spark Driver 还是 History Server，都是通过监听 event，将其中包含的任务变化信息反映到几种 UI 相关的类的实例中，然后存入KVStore供 UI 渲染。只将 KVStore 持久化下来，而不需要存储大量冗余的 event 信息。此外，KVStore原生支持了 Kryo 序列化，性能明显于 Json 序列化。


## 访问的API
 job页面：
GET   http://10.157.244.43:18081/history/application_1688369676084_1208438/1/jobs/


stage界面：
GET   http://10.157.244.43:18081/history/application_1688369676084_1208438/1/stages/


写入三类数据：
ApplicationInfo 、 LogInfo 、 ApplicationStoreInfo


界面总结：
主要的界面：
job -->  jobPages
stage  -->  stagePages
storage 
environment
Executors
SQL

界面的构成
SparkUI   ->  attachTab(new xxxPage)  ->  attachHandler(createXXXHandler)


关键数据来源：
AppStatusStore
SQLAppStatusStore


处理UI请求：
ApiRequestContext
	




[[Picture/308ccbc09418f8fa93ac64eb593eae4c_MD5.png|Open: Pasted image 20230925144909.png]]
![[Picture/308ccbc09418f8fa93ac64eb593eae4c_MD5.png]]








debug的搜索关键字：
1：一个UI的入口



KVStore类的关键方法介绍：
read(Class<T> klass, Object naturalKey):根据naturalKey获取对象并包装成kclass类型
write(Object value):将对象存入KVStore中


实现时各个注意点
文件结构：
实现方案中定义了一个文件类型：类名长度  类名   实例长度   实例内容
现有想法：不构造复杂的文件类型，在app的等级下面新建一个类名文件夹，不同的类采用同名的文件夹进行存储。

关注事件：stageEnd，JobEnd 



FsHistoryProvider写入的对象：
ApplicationInfoWrapper
ApplicationStoreInfo
LogInfo


页面与对象的存储关系
Environment						ApplicationEnvironmentInfoWrapper
ExecutionPage						SQLExecutionUIData
JobPage								JobDataWrapper
PoolPage							PoolData
StreamingQueryStatisticsPage			StreamingQueryData
AllExecutionsPage					SQLExecutionUIData
StagePage						StageDataWrapper
StoragePage						RDDStorageInfoWrapper / StreamBlockData


















History 中相关的包装类：包装类中包含的实际对象位置：api.scala
ApplicationInfoWrapper （包装类）
	val info: ApplicationInfo,
    	val attempts: List[AttemptInfoWrapper] （包装类）
		val info: ApplicationAttemptInfo,
    		val logPath: String,
    		val fileSize: Long,
    		@JsonDeserialize(contentAs = classOf[JLong])
    		val lastIndex: Option[Long],
    		val adminAcls: Option[String],
    		val viewAcls: Option[String],
    		val adminAclsGroups: Option[String],
    		val viewAclsGroups: Option[String])

	@JsonIgnore @KVIndexParam
  		def id: String = info.id







History中相关的页面展示：
History page：














