æœ¬æ–‡å·²æ”¶å½•è‡³GitHubï¼Œæ¨èé˜…è¯» ğŸ‘‰ [Javaéšæƒ³å½•](https://github.com/ZhengShuHai/JavaRecord)  
å¾®ä¿¡å…¬ä¼—å·ï¼šJavaéšæƒ³å½•

> åŸåˆ›ä¸æ˜“ï¼Œæ³¨é‡ç‰ˆæƒã€‚è½¬è½½è¯·æ³¨æ˜åŸä½œè€…å’ŒåŸæ–‡é“¾æ¥

**æ³¨ï¼šåŸæ–‡å­—æ•°è¿‡å¤šï¼Œå•ç¯‡é˜…è¯»æ—¶é—´è¿‡é•¿ï¼Œæ•…å°†æ–‡ç« æ‹†åˆ†ä¸ºä¸Šä¸‹ä¸¤ç¯‡**

åœ¨å¤§æ•°æ®æŠ€æœ¯æ ˆçš„æ¢ç´¢ä¸­ï¼Œæˆ‘ä»¬æ›¾è®¨è®ºäº†ç¦»çº¿è®¡ç®—çš„Sparkï¼Œè€Œå½“è°ˆåˆ°å®æ—¶è®¡ç®—ï¼Œå°±ä¸å¾—ä¸æFlinkã€‚æœ¬æ–‡å°†é›†ä¸­è®¨è®ºFlinkï¼Œæ—¨åœ¨è¯¦å°½å±•ç¤ºå…¶æ ¸å¿ƒæ¦‚å¿µï¼Œä»è€ŒåŠ©åŠ›ä½ åœ¨å¤§æ•°æ®æ—…ç¨‹ä¸­å‘å‰è¿ˆè¿›ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒFlinkå’ŒSparkæœ‰è®¸å¤šç›¸ä¼¼çš„æ¦‚å¿µã€‚å› æ­¤ï¼Œåœ¨æ·±å…¥å­¦ä¹ Flinkä¹‹å‰ï¼Œå»ºè®®å…ˆæµè§ˆæˆ‘ä¹‹å‰å…³äºSparkçš„æ–‡ç« ï¼Œè¿™å°†ä¸ºä½ æä¾›æ‰å®çš„åŸºç¡€ï¼Œå¹¶å¸®åŠ©åœ¨å­¦ä¹ Flinkæ—¶èƒ½æ›´å¥½åœ°ä¸¾ä¸€åä¸‰ï¼ŒåŠ æ·±å¯¹å…¶ç†è§£ã€‚

è¯ä¸å¤šè¯´ï¼Œå¼€å¯æˆ‘ä»¬çš„Flinkå­¦ä¹ ä¹‹æ—…ã€‚

## æµå¤„ç† & æ‰¹å¤„ç†

åœ¨æˆ‘ä»¬æ·±å…¥æ¢è®¨Flinkä¹‹å‰ï¼Œé¦–å…ˆè¦æŒæ¡ä¸€äº›æµè®¡ç®—çš„åŸºç¡€æ¦‚å¿µã€‚

-   **æµå¤„ç†**ï¼šæµå¤„ç†ä¸»è¦é’ˆå¯¹çš„æ˜¯æ•°æ®æµï¼Œç‰¹ç‚¹æ˜¯æ— ç•Œã€å®æ—¶ï¼Œå¯¹ç³»ç»Ÿä¼ è¾“çš„æ¯ä¸ªæ•°æ®ä¾æ¬¡æ‰§è¡Œæ“ä½œï¼Œä¸€èˆ¬ç”¨äºå®æ—¶ç»Ÿè®¡ã€‚åœ¨æµå¤„ç†ä¸­ï¼Œæ•°æ®è¢«è§†ä¸ºæ— é™è¿ç»­çš„æµï¼Œå¹¶ä¸”ä¼šå°½å¿«åœ°è¿›è¡Œå¤„ç†ã€‚Flinkåœ¨æ­¤æ¨¡å‹ä¸‹å¯ä»¥æä¾›ç§’çº§ç”šè‡³æ¯«ç§’çº§çš„å»¶è¿Ÿï¼Œä½¿å…¶æˆä¸ºéœ€è¦å¿«é€Ÿååº”å’Œå†³ç­–çš„åœºæ™¯ï¼ˆä¾‹å¦‚å®æ—¶æ¨èã€æ¬ºè¯ˆæ£€æµ‹ç­‰ï¼‰çš„ç†æƒ³é€‰æ‹©ã€‚
-   **æ‰¹å¤„ç†**ï¼šæ‰¹å¤„ç†ï¼Œä¹Ÿå«ä½œç¦»çº¿å¤„ç†ï¼Œä¸€èˆ¬ç”¨äºç¦»çº¿ç»Ÿè®¡ã€‚è¿™æ˜¯ä¸€ç§å¤„ç†å­˜å‚¨åœ¨ç³»ç»Ÿä¸­çš„é™æ€æ•°æ®é›†çš„æ¨¡å‹ã€‚åœ¨æ‰¹å¤„ç†ä¸­ï¼Œæ‰€æœ‰æ•°æ®éƒ½è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªæœ‰é™é›†åˆï¼Œå¤„ç†è¿‡ç¨‹é€šå¸¸åœ¨éäº¤äº’å¼æ¨¡å¼ä¸‹è¿›è¡Œï¼Œå³ä½œä¸šå¼€å§‹æ—¶æ‰€æœ‰æ•°æ®éƒ½å·²ç»å¯ç”¨ï¼Œä½œä¸šç»“æŸæ—¶ç»™å‡ºæ‰€æœ‰è®¡ç®—ç»“æœã€‚ç”±äºæ‰¹å¤„ç†å…è®¸å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œå…¨é¢åˆ†æï¼Œå› æ­¤å®ƒé€‚åˆäºéœ€è¦é•¿æœŸæ·±åº¦åˆ†æçš„åœºæ™¯ï¼ˆå¦‚å†å²æ•°æ®åˆ†æã€å¤§è§„æ¨¡ETLä»»åŠ¡ç­‰ï¼‰ã€‚

äº‹å®ä¸Š Flink æœ¬èº«æ˜¯æµæ‰¹ç»Ÿä¸€çš„å¤„ç†æ¶æ„ï¼Œæ‰¹é‡çš„æ•°æ®é›†æœ¬è´¨ä¸Šä¹Ÿæ˜¯æµã€‚

**åœ¨ Flink çš„è§†è§’é‡Œï¼Œä¸€åˆ‡æ•°æ®éƒ½å¯ä»¥è®¤ä¸ºæ˜¯æµï¼Œæµæ•°æ®æ˜¯æ— ç•Œæµï¼Œè€Œæ‰¹æ•°æ®åˆ™æ˜¯æœ‰ç•Œæµ**

### æ— ç•ŒæµUnbounded Streams

æ— ç•Œæµæœ‰å®šä¹‰æµçš„å¼€å§‹ï¼Œä½†æ²¡æœ‰å®šä¹‰æµçš„ç»“æŸã€‚å®ƒä»¬ä¼šæ— ä¼‘æ­¢åœ°äº§ç”Ÿæ•°æ®ã€‚æ— ç•Œæµçš„æ•°æ®å¿…é¡»æŒç»­å¤„ç†ï¼Œå³æ•°æ®è¢«æ‘„å–åéœ€è¦ç«‹åˆ»å¤„ç†ã€‚

æˆ‘ä»¬ä¸èƒ½ç­‰åˆ°æ‰€æœ‰æ•°æ®éƒ½åˆ°è¾¾å†å¤„ç†ï¼Œå› ä¸ºè¾“å…¥æ˜¯æ— é™çš„ï¼Œåœ¨ä»»ä½•æ—¶å€™è¾“å…¥éƒ½ä¸ä¼šå®Œæˆã€‚

å¤„ç†æ— ç•Œæ•°æ®é€šå¸¸è¦æ±‚ä»¥ç‰¹å®šé¡ºåºæ‘„å–äº‹ä»¶ï¼Œä¾‹å¦‚äº‹ä»¶å‘ç”Ÿçš„é¡ºåºï¼Œä»¥ä¾¿èƒ½å¤Ÿæ¨æ–­ç»“æœçš„å®Œæ•´æ€§ã€‚

### æœ‰ç•ŒæµBounded Streams

æœ‰ç•Œæµæœ‰å®šä¹‰æµçš„å¼€å§‹ï¼Œä¹Ÿæœ‰å®šä¹‰æµçš„ç»“æŸã€‚æœ‰ç•Œæµå¯ä»¥åœ¨æ‘„å–æ‰€æœ‰æ•°æ®åå†è¿›è¡Œè®¡ç®—ï¼Œæœ‰ç•Œæµæ‰€æœ‰æ•°æ®å¯ä»¥è¢«æ’åºï¼Œæ‰€ä»¥å¹¶ä¸éœ€è¦æœ‰åºæ‘„å–ã€‚

æœ‰ç•Œæµå¤„ç†é€šå¸¸è¢«ç§°ä¸ºæ‰¹å¤„ç†ã€‚æ‰€ä»¥åœ¨Flinké‡Œæ‰¹è®¡ç®—å…¶å®æŒ‡çš„å°±æ˜¯æœ‰ç•Œæµã€‚

![[Blog/Picture/1c02522625923bb82fcd3403c01e1ba8_MD5.png]]

## Flinkçš„ç‰¹ç‚¹å’Œä¼˜åŠ¿

Flinkå…·æœ‰å¦‚ä¸‹ç‰¹ç‚¹å’Œä¼˜åŠ¿ï¼š

-   åŒæ—¶æ”¯æŒé«˜ååã€ä½å»¶è¿Ÿã€é«˜æ€§èƒ½ã€‚
-   æ”¯æŒäº‹ä»¶æ—¶é—´ï¼ˆEvent Timeï¼‰æ¦‚å¿µï¼Œç»“åˆWatermarkå¤„ç†ä¹±åºæ•°æ®ã€‚
-   æ”¯æŒæœ‰çŠ¶æ€è®¡ç®—ï¼Œå¹¶ä¸”æ”¯æŒå¤šç§çŠ¶æ€å†…å­˜ã€ æ–‡ä»¶ã€RocksDBã€‚
-   æ”¯æŒé«˜åº¦çµæ´»çš„çª—å£ï¼ˆWindowï¼‰ æ“ä½œ timeã€ countã€ sessionç­‰ã€‚
-   åŸºäºè½»é‡çº§åˆ†å¸ƒå¼å¿«ç…§ï¼ˆCheckPointï¼‰ å®ç°çš„å®¹é”™ä¿è¯Exactly- Onceè¯­ä¹‰ã€‚
-   åŸºäºJVMå®ç°ç‹¬ç«‹çš„å†…å­˜ç®¡ç†ã€‚

## Flink VS Spark

Spark å’Œ Flink åœ¨ä¸åŒçš„åº”ç”¨é¢†åŸŸä¸Šè¡¨ç°ä¼šæœ‰å·®åˆ«ã€‚

ä¸€èˆ¬æ¥è¯´ï¼ŒSpark åŸºäºå¾®æ‰¹å¤„ç†çš„æ–¹å¼åšåŒæ­¥æ€»æœ‰ä¸€ä¸ªâ€œæ”’æ‰¹â€çš„è¿‡ç¨‹ï¼Œæ‰€ä»¥ä¼šæœ‰é¢å¤–å¼€é”€ï¼Œå› æ­¤æ— æ³•åœ¨æµå¤„ç†çš„ä½å»¶è¿Ÿä¸Šåšåˆ°æè‡´ã€‚

**åœ¨ä½å»¶è¿Ÿæµå¤„ç†åœºæ™¯ï¼ŒFlink å·²ç»æœ‰æ˜æ˜¾çš„ä¼˜åŠ¿ã€‚è€Œåœ¨æµ·é‡æ•°æ®çš„æ‰¹å¤„ç†é¢†åŸŸï¼ŒSpark èƒ½å¤Ÿå¤„ç†çš„ååé‡æ›´å¤§**

å¦å¤–ï¼ŒSpark Streamingä¸­çš„æµè®¡ç®—å…¶å®æ˜¯å¾®æ‰¹è®¡ç®—ï¼Œå®æ—¶æ€§ä¸å¦‚Flinkï¼Œè¿˜æœ‰ä¸€ç‚¹å¾ˆé‡è¦çš„æ˜¯Spark Streamingä¸é€‚åˆæœ‰çŠ¶æ€çš„è®¡ç®—ï¼Œå¾—å€ŸåŠ©ä¸€äº›å­˜å‚¨å¦‚ï¼šRedisï¼Œæ‰èƒ½å®ç°ã€‚è€ŒFlinkå¤©ç„¶æ”¯æŒæœ‰çŠ¶æ€çš„è®¡ç®—ã€‚

## Flink API

Flink æœ¬èº«æä¾›äº†å¤šå±‚ APIï¼š

![[Blog/Picture/ba0282398c7516b5dc3b347837c8db94_MD5.png]]

-   **Stateful Stream Processing** ï¼šæœ€ä½çº§çš„æŠ½è±¡æ¥å£æ˜¯çŠ¶æ€åŒ–çš„æ•°æ®æµæ¥å£ï¼ˆstateful streamingï¼‰ã€‚è¿™ä¸ªæ¥å£æ˜¯é€šè¿‡ ProcessFunction é›†æˆåˆ° DataStream API ä¸­çš„ã€‚è¯¥æ¥å£å…è®¸ç”¨æˆ·è‡ªç”±çš„å¤„ç†æ¥è‡ªä¸€ä¸ªæˆ–å¤šä¸ªæµä¸­çš„äº‹ä»¶ï¼Œå¹¶ä½¿ç”¨ä¸€è‡´çš„å®¹é”™çŠ¶æ€ã€‚å¦å¤–ï¼Œç”¨æˆ·ä¹Ÿå¯ä»¥é€šè¿‡æ³¨å†Œ event time å’Œ processing time å¤„ç†å›è°ƒå‡½æ•°çš„æ–¹æ³•æ¥å®ç°å¤æ‚çš„è®¡ç®—ã€‚
-   **DataStream/DataSet API**ï¼š DataStream / DataSet API æ˜¯ Flink æä¾›çš„æ ¸å¿ƒ API ï¼ŒDataSet å¤„ç†æœ‰ç•Œçš„æ•°æ®é›†ï¼ŒDataStream å¤„ç†æœ‰ç•Œæˆ–è€…æ— ç•Œçš„æ•°æ®æµã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡å„ç§æ–¹æ³•ï¼ˆmap / flatmap / window / keyby / sum / max / min / avg / join ç­‰ï¼‰å°†æ•°æ®è¿›è¡Œè½¬æ¢ / è®¡ç®—ã€‚
-   **Table API**ï¼š Table API æä¾›äº†ä¾‹å¦‚ selectã€projectã€joinã€group-byã€aggregate ç­‰æ“ä½œï¼Œä½¿ç”¨èµ·æ¥å´æ›´åŠ ç®€æ´ï¼Œå¯ä»¥åœ¨è¡¨ä¸ DataStream/DataSet ä¹‹é—´æ— ç¼åˆ‡æ¢ï¼Œä¹Ÿå…è®¸ç¨‹åºå°† Table API ä¸ DataStream ä»¥åŠ DataSet æ··åˆä½¿ç”¨ã€‚
-   **SQL**ï¼š Flink æä¾›çš„æœ€é«˜å±‚çº§çš„æŠ½è±¡æ˜¯ Flink SQLï¼Œè¿™ä¸€å±‚æŠ½è±¡åœ¨è¯­æ³•ä¸è¡¨è¾¾èƒ½åŠ›ä¸Šä¸ Table API ç±»ä¼¼ï¼ŒSQL æŠ½è±¡ä¸ Table API äº¤äº’å¯†åˆ‡ï¼ŒåŒæ—¶ SQL æŸ¥è¯¢å¯ä»¥ç›´æ¥åœ¨ Table API å®šä¹‰çš„è¡¨ä¸Šæ‰§è¡Œã€‚

## Dataflowsæ•°æ®æµå›¾

æ‰€æœ‰çš„ Flink ç¨‹åºéƒ½å¯ä»¥å½’çº³ä¸ºç”±ä¸‰éƒ¨åˆ†æ„æˆï¼š`Source`ã€`Transformation` å’Œ `Sink`ã€‚

-   Source è¡¨ç¤ºâ€œæºç®—å­â€ï¼Œè´Ÿè´£è¯»å–æ•°æ®æºã€‚
    
-   Transformation è¡¨ç¤ºâ€œè½¬æ¢ç®—å­â€ï¼Œåˆ©ç”¨å„ç§ç®—å­è¿›è¡Œå¤„ç†åŠ å·¥ã€‚
    
-   Sink è¡¨ç¤ºâ€œä¸‹æ²‰ç®—å­â€ï¼Œè´Ÿè´£æ•°æ®çš„è¾“å‡ºã€‚
    

Sourceæ•°æ®æºä¼šæºæºä¸æ–­çš„äº§ç”Ÿæ•°æ®ï¼ŒTransformationå°†äº§ç”Ÿçš„æ•°æ®è¿›è¡Œå„ç§ä¸šåŠ¡é€»è¾‘çš„æ•°æ®å¤„ç†ï¼Œæœ€ç»ˆç”±Sinkè¾“å‡ºåˆ°å¤–éƒ¨ï¼ˆconsoleã€kafkaã€redisã€DB......ï¼‰ã€‚

æ‰€æœ‰åŸºäºFlinkå¼€å‘çš„ç¨‹åºéƒ½èƒ½å¤Ÿæ˜ å°„æˆä¸€ä¸ªDataflowsï¼ˆæ•°æ®æµå›¾ï¼‰ï¼š

![[Blog/Picture/2944840bdb874ee0c7525ebc87675f7d_MD5.png]]

å½“Sourceæ•°æ®æºçš„æ•°é‡æ¯”è¾ƒå¤§æˆ–è®¡ç®—é€»è¾‘ç›¸å¯¹æ¯”è¾ƒå¤æ‚çš„æƒ…å†µä¸‹ï¼Œéœ€è¦æé«˜å¹¶è¡Œåº¦æ¥å¤„ç†æ•°æ®ï¼Œé‡‡ç”¨å¹¶è¡Œæ•°æ®æµã€‚

é€šè¿‡è®¾ç½®ä¸åŒç®—å­çš„å¹¶è¡Œåº¦ï¼Œæ¯”å¦‚ Sourceå¹¶è¡Œåº¦è®¾ç½®ä¸º2 ï¼Œmapä¹Ÿæ˜¯2ã€‚ä»£è¡¨ä¼šå¯åŠ¨2ä¸ªå¹¶è¡Œçš„çº¿ç¨‹æ¥å¤„ç†æ•°æ®ï¼š

![[Blog/Picture/175a42b2d587e5da16afe725927d7bc1_MD5.png]]

## Job Manager & Task Manager

Flinkæ˜¯ä¸€ä¸ªå…¸å‹çš„Master-Slaveæ¶æ„ï¼Œæ¶æ„ä¸­åŒ…å«äº†ä¸¤ä¸ªé‡è¦è§’è‰²ï¼Œåˆ†åˆ«æ˜¯ã€Œ**JobManager**ã€å’Œã€Œ**TaskManager**ã€ã€‚

JobManagerç›¸å½“äºæ˜¯Masterï¼ŒTaskManagerç›¸å½“äºæ˜¯Slaveã€‚

![[Blog/Picture/27fed4d4f7f5da380640b2371d70f045_MD5.png]]

åœ¨Flinkä¸­ï¼ŒJobManagerè´Ÿè´£æ•´ä¸ªFlinké›†ç¾¤ä»»åŠ¡çš„è°ƒåº¦ä»¥åŠèµ„æºçš„ç®¡ç†ã€‚å®ƒä»å®¢æˆ·ç«¯ä¸­è·å–æäº¤çš„åº”ç”¨ï¼Œç„¶åæ ¹æ®é›†ç¾¤ä¸­TaskManagerä¸ŠTaskSlotçš„ä½¿ç”¨æƒ…å†µï¼Œä¸ºæäº¤çš„åº”ç”¨åˆ†é…ç›¸åº”çš„TaskSlotèµ„æºå¹¶å‘½ä»¤TaskManagerå¯åŠ¨ä»å®¢æˆ·ç«¯ä¸­è·å–çš„åº”ç”¨ã€‚

TaskManageråˆ™è´Ÿè´£æ‰§è¡Œä½œä¸šæµçš„Taskï¼Œå¹¶ä¸”ç¼“å­˜å’Œäº¤æ¢æ•°æ®æµã€‚

åœ¨TaskManagerä¸­èµ„æºè°ƒåº¦çš„æœ€å°å•ä½æ˜¯Task slotã€‚TaskManagerä¸­Task slotçš„æ•°é‡è¡¨ç¤ºå¹¶å‘å¤„ç†Taskçš„æ•°é‡ã€‚

**ä¸€å°æœºå™¨èŠ‚ç‚¹å¯ä»¥è¿è¡Œå¤šä¸ªTaskManagerï¼ŒTaskManagerå·¥ä½œæœŸé—´ä¼šå‘JobManagerå‘é€å¿ƒè·³ä¿æŒè¿æ¥**

## éƒ¨ç½² & è¿è¡Œ

### éƒ¨ç½²æ¨¡å¼

Flinkæ”¯æŒå¤šç§éƒ¨ç½²æ¨¡å¼ï¼ŒåŒ…æ‹¬æœ¬åœ°æ¨¡å¼ã€Standaloneæ¨¡å¼ã€YARNæ¨¡å¼ã€Mesosæ¨¡å¼å’ŒKubernetesæ¨¡å¼ã€‚

-   **æœ¬åœ°æ¨¡å¼**ï¼šæœ¬åœ°æ¨¡å¼æ˜¯åœ¨å•ä¸ªJVMä¸­å¯åŠ¨Flinkï¼Œä¸»è¦ç”¨äºå¼€å‘å’Œæµ‹è¯•ã€‚å®ƒä¸éœ€è¦ä»»ä½•é›†ç¾¤ç®¡ç†å™¨ï¼Œä½†ä¹Ÿä¸èƒ½è·¨å¤šå°æœºå™¨è¿è¡Œã€‚æœ¬åœ°æ¨¡å¼çš„ä¼˜ç‚¹æ˜¯éƒ¨ç½²ç®€å•ï¼Œç¼ºç‚¹æ˜¯ä¸èƒ½åˆ©ç”¨åˆ†å¸ƒå¼è®¡ç®—çš„ä¼˜åŠ¿ã€‚
-   **Standaloneæ¨¡å¼**ï¼šStandaloneæ¨¡å¼æ˜¯åœ¨ä¸€ä¸ªç‹¬ç«‹çš„é›†ç¾¤ä¸­è¿è¡ŒFlinkã€‚å®ƒéœ€è¦æ‰‹åŠ¨å¯åŠ¨Flinké›†ç¾¤ï¼Œå¹¶ä¸”éœ€è¦æ‰‹åŠ¨ç®¡ç†èµ„æºã€‚Standaloneæ¨¡å¼çš„ä¼˜ç‚¹æ˜¯éƒ¨ç½²ç®€å•ï¼Œå¯ä»¥è·¨å¤šå°æœºå™¨è¿è¡Œï¼Œç¼ºç‚¹æ˜¯éœ€è¦æ‰‹åŠ¨ç®¡ç†èµ„æºã€‚
-   **YARNæ¨¡å¼**ï¼šåœ¨è¿™ä¸ªæ¨¡å¼ä¸‹ï¼ŒFlinkä½œä¸ºYARNçš„ä¸€ä¸ªåº”ç”¨ç¨‹åºè¿è¡Œåœ¨YARNé›†ç¾¤ä¸­ã€‚Flinkä¼šä»YARNè·å–æ‰€éœ€çš„èµ„æºæ¥è¿è¡ŒJobManagerå’ŒTaskManagerã€‚å¦‚æœä½ å·²ç»æœ‰äº†ä¸€ä¸ªè¿è¡ŒHadoop/YARNçš„å¤§æ•°æ®å¹³å°ï¼Œé€‰æ‹©è¿™ä¸ªæ¨¡å¼å¯ä»¥æ–¹ä¾¿åœ°åˆ©ç”¨å·²æœ‰çš„èµ„æºï¼Œè¿™æ˜¯ä¼ä¸šä¸­ç”¨çš„æ¯”è¾ƒå¤šçš„æ–¹å¼ã€‚
-   **Mesosæ¨¡å¼**ï¼šMesosæ˜¯ä¸€ä¸ªæ›´é€šç”¨çš„é›†ç¾¤ç®¡ç†æ¡†æ¶ï¼Œå¯ä»¥è¿è¡ŒéJavaåº”ç”¨ç¨‹åºï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„å®¹é”™æ€§å’Œä¼¸ç¼©æ€§ã€‚Flinkåœ¨Mesosä¸Šçš„è¿è¡Œæ–¹å¼ä¸åœ¨YARNä¸Šç±»ä¼¼ï¼Œä¹Ÿæ˜¯ä»Mesosè¯·æ±‚èµ„æºæ¥è¿è¡ŒJobManagerå’ŒTaskManagerã€‚
-   **Kubernetesæ¨¡å¼**ï¼šKubernetesæ˜¯ä¸€ä¸ªå¼€æºçš„å®¹å™¨ç¼–æ’å¹³å°ã€‚Flinkå¯ä»¥ä½œä¸ºä¸€ç»„åˆ†å¸ƒå¼çš„Dockerå®¹å™¨åœ¨Kubernetesé›†ç¾¤ä¸Šè¿è¡Œã€‚Kubernetesæä¾›äº†è‡ªåŠ¨åŒ–ã€æ‰©å±•å’Œç®¡ç†åº”ç”¨ç¨‹åºå®¹å™¨çš„åŠŸèƒ½ï¼Œå¯¹äºäº‘åŸç”Ÿåº”ç”¨ç¨‹åºéƒ¨ç½²éå¸¸åˆé€‚ã€‚

æ¯ç§éƒ¨ç½²æ¨¡å¼éƒ½æœ‰å…¶ä¼˜ç¼ºç‚¹ï¼Œé€‰æ‹©å“ªç§éƒ¨ç½²æ¨¡å¼å–å†³äºå…·ä½“çš„åº”ç”¨åœºæ™¯å’Œéœ€æ±‚ã€‚

### è¿è¡Œæ¨¡å¼

Flink æœ‰ä¸‰ç§ä¸åŒçš„è¿è¡Œæ¨¡å¼ï¼šSessionã€Per-Job å’Œ Applicationã€‚

-   **Session**ï¼šåœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œä¸€ä¸ª Flink é›†ç¾¤ä¼šè¢«å¯åŠ¨ä¸”ä¼šä¸€ç›´è¿è¡Œï¼Œç›´åˆ°æ˜ç¡®åœ°è¢«ç»ˆæ­¢ã€‚ç”¨æˆ·å¯ä»¥åœ¨è¿™ä¸ªé›†ç¾¤ä¸­æäº¤å¤šä¸ªä½œä¸šã€‚è¿™ä¸ªæ¨¡å¼é€‚åˆå¤šä¸ªçŸ­ä½œä¸šçš„åœºæ™¯ã€‚
-   **Per-Job**ï¼šåœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œå¯¹äºæ¯ä¸ªæäº¤çš„ä½œä¸šï¼Œéƒ½ä¼šå¯åŠ¨ä¸€ä¸ªæ–°çš„ Flink é›†ç¾¤ï¼Œç„¶åå†æ‰§è¡Œè¯¥ä½œä¸šã€‚ä½œä¸šå®Œæˆåï¼Œç›¸åº”çš„ Flink é›†ç¾¤ä¹Ÿä¼šè¢«ç»ˆæ­¢ã€‚è¿™ç§æ¨¡å¼é€‚åˆé•¿æ—¶é—´è¿è¡Œçš„ä½œä¸šã€‚
-   **Application**ï¼šè¿™ç§æ¨¡å¼æ˜¯ä¸€ç§ç‰¹æ®Šçš„ Per-Job æ¨¡å¼ï¼Œå®ƒå…è®¸ç”¨æˆ·ä»¥ååº”å¼çš„æ–¹å¼ä¸ä½œä¸šè¿›è¡Œäº¤äº’ï¼ˆæ¯”å¦‚ï¼Œä½¿ç”¨ DataStream APIï¼‰ã€‚è¿™æ˜¯ Flink 1.11 ç‰ˆæœ¬å¼•å…¥çš„æ–°æ¨¡å¼ï¼Œå®ƒç»“åˆäº†Sessionæ¨¡å¼å’ŒPer-Jobæ¨¡å¼çš„ä¼˜ç‚¹ã€‚åœ¨Applicationæ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªä½œä¸šéƒ½ä¼šå¯åŠ¨ä¸€ä¸ªç‹¬ç«‹çš„Flinké›†ç¾¤ï¼Œä½†æ˜¯ä½œä¸šæäº¤å¿«ã€‚

ä»¥ä¸Šæ‰€è¿°çš„éƒ¨ç½²ç¯å¢ƒå¯ä»¥ä¸ä»»ä½•ä¸€ç§è¿è¡Œæ¨¡å¼ç»“åˆä½¿ç”¨ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥åœ¨æœ¬åœ°æ¨¡å¼ã€Standalone æ¨¡å¼æˆ– YARN æ¨¡å¼ä¸‹è¿è¡Œ Sessionã€Per-Job æˆ– Application æ¨¡å¼çš„ Flink ä½œä¸šã€‚

### æäº¤å’Œæ‰§è¡Œä½œä¸šæµç¨‹

Flinkåœ¨ä¸åŒè¿è¡Œæ¨¡å‹ä¸‹çš„ä½œä¸šæäº¤å’Œæ‰§è¡Œæµç¨‹å¤§è‡´å¦‚ä¸‹ï¼š

-   **Session æ¨¡å¼**ï¼š
    
    -   å¯åŠ¨Flinké›†ç¾¤ï¼šåœ¨Sessionæ¨¡å¼ä¸‹ï¼Œé¦–å…ˆéœ€è¦å¯åŠ¨ä¸€ä¸ªè¿è¡Œä¸­çš„Flinké›†ç¾¤ã€‚è¿™ä¸ªé›†ç¾¤å¯ä»¥æ˜¯Standalone Session Clusterï¼Œä¹Ÿå¯ä»¥æ˜¯åœ¨Yarnæˆ–Kubernetesç­‰èµ„æºç®¡ç†å™¨ä¸Šçš„Session Clusterã€‚
    -   ä½œä¸šæäº¤ï¼šç„¶åï¼Œç”¨æˆ·é€šè¿‡Flinkå®¢æˆ·ç«¯ï¼ˆä¾‹å¦‚CLIã€REST APIæˆ–Web UIï¼‰å°†ä½œä¸šæäº¤ç»™Flink DispatcheræœåŠ¡ã€‚DispatcheræœåŠ¡æ˜¯Flinké›†ç¾¤çš„ä¸»è¦å…¥å£ç‚¹ï¼Œè´Ÿè´£æ¥æ”¶å’Œåè°ƒä½œä¸šè¯·æ±‚ã€‚
    -   ä½œä¸šè§£æä¸ä¼˜åŒ–ï¼šä¸€æ—¦Flink Dispatcheræ¥æ”¶åˆ°ä½œä¸šï¼Œå®ƒä¼šå¯¹ä½œä¸šæ‰§è¡Œå›¾ï¼ˆJobGraphï¼‰è¿›è¡Œè§£æï¼Œå¹¶ä½¿ç”¨Flinkçš„ä¼˜åŒ–å™¨å¯¹æ‰§è¡Œå›¾è¿›è¡Œä¼˜åŒ–ã€‚
    -   åˆ›å»ºä½œä¸šæ‰§è¡Œç¯å¢ƒï¼šDispatcherä¼šä¸ºæ–°çš„ä½œä¸šåˆ›å»ºä¸€ä¸ªJobManagerï¼Œè¿™ä¸ªJobManagerå°±æ˜¯ä¸€æ¬¡ä½œä¸šçš„æ‰§è¡Œç¯å¢ƒã€‚å¹¶ä¸”ï¼Œæ¯ä¸ªJobéƒ½æœ‰å±äºè‡ªå·±çš„JobManagerã€‚
    -   ä½œä¸šæ‰§è¡Œï¼šJobManagerå°†ä¼˜åŒ–åçš„æ‰§è¡Œå›¾å‘é€åˆ°TaskManagerèŠ‚ç‚¹æ¥æ‰§è¡Œå…·ä½“çš„ä»»åŠ¡ã€‚TaskManagerèŠ‚ç‚¹åŒ…å«è‹¥å¹²ä¸ªslotï¼Œæ¯ä¸ªslotå¯ä»¥è¿è¡Œä½œä¸šå›¾ä¸­çš„ä¸€ä¸ªå¹¶è¡Œæ“ä½œã€‚
    -   ç»“æœå’ŒçŠ¶æ€ç®¡ç†ï¼šä½œä¸šæ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œè¾“å‡ºç»“æœè¢«å‘é€å›JobManagerï¼Œå¹¶æä¾›ç»™ç”¨æˆ·ã€‚åŒæ—¶ï¼Œä½œä¸šçš„çŠ¶æ€ä¹Ÿç”±JobManagerç®¡ç†ï¼Œä»¥æ”¯æŒæ•…éšœæ¢å¤ã€‚
    
    å½“ä½ çš„ä½œä¸šå®Œæˆè¿è¡Œåï¼Œè¯¥ä½œä¸šçš„JobManagerä¼šè¢«åœæ­¢ï¼Œä½†æ˜¯Flinké›†ç¾¤ï¼ˆåŒ…æ‹¬Dispatcherå’Œå…¶ä½™çš„TaskManagerï¼‰ä»ç„¶å¤„äºè¿è¡ŒçŠ¶æ€ï¼Œç­‰å¾…æ–°çš„ä½œä¸šæäº¤ã€‚è¿™å°±æ˜¯æ‰€è°“çš„Sessionæ¨¡å¼ï¼Œå®ƒå…è®¸åœ¨åŒä¸€ä¸ªFlinké›†ç¾¤ä¸Šè¿ç»­è¿è¡Œå¤šä¸ªä½œä¸šã€‚
    
-   **Per-Job æ¨¡å¼**ï¼š
    
    -   ç”¨æˆ·é€šè¿‡å‘½ä»¤è¡Œæˆ–è€…UIå°†ç¨‹åºåŒ…å«æ‰€æœ‰ä¾èµ–æäº¤åˆ°Flinké›†ç¾¤ã€‚
    -   Flink MasterèŠ‚ç‚¹æ¥æ”¶åˆ°ç”¨æˆ·æäº¤çš„ä½œä¸šåï¼Œä¼šå¯åŠ¨ä¸€ä¸ªæ–°çš„JobManageræ¥è´Ÿè´£è¿™ä¸ªä½œä¸šçš„èµ„æºç®¡ç†ä¸ä»»åŠ¡è°ƒåº¦ã€‚
    -   JobManageré€šè¿‡ResourceManagerå‘Flinké›†ç¾¤è¯·æ±‚æ‰€éœ€çš„TaskManagerèµ„æºã€‚
    -   ResourceManageråˆ†é…TaskManagerç»™JobManagerï¼Œå¹¶å¯åŠ¨TaskManagerè¿›ç¨‹ã€‚
    -   TaskManagerå‘JobManageræ³¨å†Œå¹¶æä¾›è‡ªå·±çš„çŠ¶æ€åŠå¯ç”¨çš„slotä¿¡æ¯ã€‚
    -   JobManageræ ¹æ®ç¨‹åºçš„DAGå›¾è®¡ç®—å‡ºExecutionGraphï¼Œç„¶åæŒ‰ç…§stageså°†ç›¸åº”çš„tasksåˆ†é…åˆ°TaskManagerçš„Slotsä¸­å»æ‰§è¡Œã€‚
    -   å¦‚æœä½œä¸šæ‰§è¡Œå®Œæ¯•æˆ–æ‰§è¡Œå¤±è´¥ï¼ŒJobManagerä¼šé‡Šæ”¾æ‰€æœ‰èµ„æºï¼Œå¹¶å°†ç»“æœè¿”å›ç»™ç”¨æˆ·ã€‚
    
    åœ¨Per-Jobæ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªä½œä¸šéƒ½æœ‰è‡ªå·±çš„èµ„æºéš”ç¦»ï¼Œäº’ä¸å¹²æ‰°ï¼Œèµ„æºåˆ©ç”¨ç‡è¾ƒé«˜ï¼Œä½†æ˜¯å¦‚æœä½œä¸šæ•°é‡å¤§ï¼Œåˆ™å¯èƒ½ä¼šå› ä¸ºæ¯ä¸ªä½œä¸šéƒ½éœ€è¦å•ç‹¬ç”³è¯·ã€é‡Šæ”¾èµ„æºå¯¼è‡´æ•ˆç‡è¾ƒä½ã€‚
    
-   **Application æ¨¡å¼**ï¼š
    
    -   æ„å»ºFlink Jobï¼šå®¢æˆ·ç«¯æˆ–è€…ç”¨æˆ·åœ¨æœ¬åœ°ç¯å¢ƒä¸Šæ„å»ºFlinkä½œä¸šã€‚
    -   æäº¤Flink Jobï¼šé€šè¿‡Flinkå‘½ä»¤è¡Œå·¥å…·æˆ–è€…Web UIï¼Œå°†åºåˆ—åŒ–åçš„JobGraphæäº¤åˆ°Flinké›†ç¾¤ã€‚ä¹Ÿå¯ä»¥é€šè¿‡REST APIç›´æ¥æäº¤ä½œä¸šã€‚
    -   JobManageræ¥æ”¶Jobï¼šJobManageræ˜¯Flinkä¸­è´Ÿè´£ä»»åŠ¡è°ƒåº¦å’Œåè°ƒçš„ç»„ä»¶ã€‚å®ƒä¼šæ¥æ”¶åˆ°æäº¤çš„JobGraphï¼Œå¹¶å°†å…¶å°è£…æˆExecutionGraphã€‚
    -   ä»»åŠ¡è°ƒåº¦ï¼šJobManagerä¼šæ ¹æ®ExecutionGraphå¯¹ä»»åŠ¡è¿›è¡Œè°ƒåº¦ï¼Œå†³å®šä½•æ—¶å¯åŠ¨ä»»åŠ¡ï¼Œä»¥åŠå“ªä¸ªTaskManagerä¸Šå¯åŠ¨ä»»åŠ¡ã€‚
    -   ä»»åŠ¡æ‰§è¡Œï¼šTaskManageræ¥æ”¶åˆ°JobManageråˆ†é…çš„ä»»åŠ¡åå¼€å§‹æ‰§è¡Œã€‚æ¯ä¸ªTaskManageråŒ…å«ä¸€åˆ°å¤šä¸ªSlotï¼Œè¿™äº›Slotç”¨äºè¿è¡Œä»»åŠ¡ã€‚
    -   çŠ¶æ€åé¦ˆï¼šTaskManageråœ¨æ‰§è¡Œä»»åŠ¡è¿‡ç¨‹ä¸­ä¼šå°†çŠ¶æ€ä¿¡æ¯ï¼ˆå¦‚è¿›åº¦ã€æ—¥å¿—ç­‰ï¼‰åé¦ˆç»™JobManagerã€‚
    -   ç»“æœè¿”å›ï¼šå½“æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆåï¼ŒJobManagerä¼šå°†æ‰§è¡Œç»“æœè¿”å›ç»™å®¢æˆ·ç«¯ã€‚

## é…ç½®å¼€å‘ç¯å¢ƒ

æ¯ä¸ª Flink åº”ç”¨éƒ½éœ€è¦ä¾èµ–ä¸€ç»„ Flink ç±»åº“ã€‚Flink åº”ç”¨è‡³å°‘éœ€è¦ä¾èµ– Flink APIsã€‚è®¸å¤šåº”ç”¨è¿˜ä¼šé¢å¤–ä¾èµ–è¿æ¥å™¨ç±»åº“(æ¯”å¦‚ Kafkaã€Cassandra ç­‰)ã€‚ å½“ç”¨æˆ·è¿è¡Œ Flink åº”ç”¨æ—¶(æ— è®ºæ˜¯åœ¨ IDEA ç¯å¢ƒä¸‹è¿›è¡Œæµ‹è¯•ï¼Œè¿˜æ˜¯éƒ¨ç½²åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹)ï¼Œè¿è¡Œæ—¶ç±»åº“éƒ½å¿…é¡»å¯ç”¨ã€‚

å¼€å‘å·¥å…·ï¼šIntelliJ IDEA

ä»¥Javaè¯­è¨€ä¸ºä¾‹ï¼Œé…ç½®å¼€å‘Mavenä¾èµ–ï¼š

```xml
<properties> <flink.version>1.13.6</flink.version> <scala.binary.version>2.12</scala.binary.version> <maven.compiler.source>1.8</maven.compiler.source> <maven.compiler.target>1.8</maven.compiler.target> </properties> <dependencies> <dependency> <groupId>org.apache.flink</groupId> <artifactId>flink-java</artifactId> <version>${flink.version}</version> </dependency> <dependency> <groupId>org.apache.flink</groupId> <artifactId>flink-streaming-java_${scala.binary.version}</artifactId> <version>${flink.version}</version> </dependency> <dependency> <groupId>org.apache.flink</groupId> <artifactId>flink-clients_${scala.binary.version}</artifactId> <version>${flink.version}</version> </dependency> </dependencies>
```

**æ³¨æ„ç‚¹**ï¼š

-   å¦‚æœè¦å°†ç¨‹åºæ‰“åŒ…æäº¤åˆ°é›†ç¾¤è¿è¡Œï¼Œæ‰“åŒ…çš„æ—¶å€™ä¸éœ€è¦åŒ…å«è¿™äº›ä¾èµ–ï¼Œå› ä¸ºé›†ç¾¤ç¯å¢ƒå·²ç»åŒ…å«äº†è¿™äº›ä¾èµ–ï¼Œæ­¤æ—¶ä¾èµ–çš„ä½œç”¨åŸŸåº”è¯¥è®¾ç½®ä¸º`provided`ã€‚
-   Flink åº”ç”¨åœ¨ IntelliJ IDEA ä¸­è¿è¡Œï¼Œè¿™äº› Flink æ ¸å¿ƒä¾èµ–çš„ä½œç”¨åŸŸéœ€è¦è®¾ç½®ä¸º `compile` è€Œä¸æ˜¯ `provided` ã€‚ å¦åˆ™ IntelliJ ä¸ä¼šæ·»åŠ è¿™äº›ä¾èµ–åˆ° classpathï¼Œä¼šå¯¼è‡´åº”ç”¨è¿è¡Œæ—¶æŠ›å‡º `NoClassDefFountError` å¼‚å¸¸ã€‚

æ·»åŠ æ‰“åŒ…æ’ä»¶ï¼š

```xml
<build> <plugins> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-shade-plugin</artifactId> <version>3.2.4</version> <executions> <execution> <phase>package</phase> <goals> <goal>shade</goal> </goals> <configuration> <artifactSet> <excludes> <exclude>org.apache.flink:force-shading</exclude> <exclude>com.google.code.findbugs:jsr305</exclude> <exclude>org.slf4j:*</exclude> <exclude>log4j:*</exclude> </excludes> </artifactSet> <filters> <filter> <artifact>*:*</artifact> <excludes> <exclude>META-INF/*.SF</exclude> <exclude>META-INF/*.DSA</exclude> <exclude>META-INF/*.RSA</exclude> </excludes> </filter> </filters> </configuration> </execution> </executions> </plugin> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-compiler-plugin</artifactId> <version>3.8.0</version> <configuration> <source>1.8</source> <target>1.8</target> </configuration> </plugin> </plugins> </build>
```

### WordCountç¨‹åº

é…ç½®å¥½å¼€å‘ç¯å¢ƒä¹‹åæˆ‘ä»¬æ¥å†™ä¸€ä¸ªç®€å•çš„Flinkç¨‹åºã€‚

éœ€æ±‚ï¼šç»Ÿè®¡å•è¯å‡ºç°çš„æ¬¡æ•°

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // è®¾ç½®å¹¶è¡Œåº¦ä¸º 1 env.setParallelism(1); // æ„å»ºè¾“å…¥æ•°æ®æµ DataStream<String> text = env.fromElements( "Hello World", "Hello Flink", "Hello Java"); // å¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ“ä½œï¼ŒåŒ…æ‹¬åˆ†å‰²ã€æ˜ å°„å’Œèšåˆ DataStream<Tuple2<String, Integer>> counts = text .flatMap(new Tokenizer()) //keyBy(0) æ“ä½œæŒ‰ç…§å…ƒç»„çš„ç¬¬ä¸€ä¸ªå­—æ®µï¼ˆç´¢å¼•ä¸º0ï¼‰è¿›è¡Œåˆ†ç»„ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œè¿™å°±è¡¨ç¤ºæ ¹æ®æ¯ä¸ªå•è¯ï¼ˆå­—ç¬¦ä¸²ï¼‰è¿›è¡Œåˆ†ç»„ã€‚ .keyBy(0) //sum(1) æ˜¯ä¸€ä¸ªèšåˆæ“ä½œï¼Œå®ƒå¯¹æ¯ä¸ªåˆ†ç»„å†…çš„å…ƒç´ è¿›è¡Œæ±‚å’Œã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå¯¹å…ƒç»„çš„ç¬¬äºŒä¸ªå­—æ®µï¼ˆç´¢å¼•ä¸º1ï¼‰è¿›è¡Œæ±‚å’Œï¼Œè¡¨ç¤ºæ¯ä¸ªå•è¯çš„å‡ºç°æ¬¡æ•°ã€‚ .sum(1); // è¾“å‡ºç»“æœ counts.print(); // æ‰§è¡Œä»»åŠ¡ env.execute("Flink Streaming Java WordCount"); } public static final class Tokenizer implements FlatMapFunction<String, Tuple2<String, Integer>> { @Override public void flatMap(String value, Collector<Tuple2<String, Integer>> out) { // è§„èŒƒåŒ–å¹¶åˆ†å‰²è¡Œ String[] words = value.toLowerCase().split("\\W+"); // ä¸ºæ¯ä¸ªå•è¯å‘å‡º Tuple2<String, Integer>(word, 1) for (String word : words) { if (word.length() > 0) { out.collect(new Tuple2<>(word, 1)); } } } }
```

è¾“å‡ºå¦‚ä¸‹ï¼š

```scss
(hello,1) (world,1) (hello,2) (flink,1) (hello,3) (java,1)
```

å¯¹ä»£ç ç®€è¦è§£æä¸€ä¸‹ï¼š

è¿™æ˜¯ä¸€ä¸ªåŸºæœ¬çš„å•è¯è®¡æ•°ç¨‹åºï¼Œå®ƒä½¿ç”¨Apache Flinkçš„æµå¤„ç†ç¯å¢ƒã€‚è¿™ä¸ªç¨‹åºè¯»å…¥ä¸€ç³»åˆ—çš„å­—ç¬¦ä¸²ï¼Œç„¶åæŠŠæ¯ä¸ªå­—ç¬¦ä¸²åˆ†å‰²æˆå•è¯ï¼Œå¯¹æ¯ä¸ªå•è¯è¿›è¡Œè®¡æ•°ï¼Œå¹¶ä¸”è¾“å‡ºè®¡æ•°ç»“æœã€‚

åœ¨æä¾›çš„ä¾‹å­ä¸­ï¼Œæœ‰ä¸‰ä¸ªè¾“å…¥å­—ç¬¦ä¸²ï¼š"Hello World", "Hello Flink", "Hello Java"ï¼Œ'Hello'è¿™ä¸ªå•è¯å‡ºç°äº†ä¸‰æ¬¡ï¼Œå…¶ä½™å•è¯ ('World', 'Flink', 'Java') å„å‡ºç°äº†ä¸€æ¬¡ã€‚

ç”±äºFlinkæ˜¯ä¸€ä¸ªæµå¤„ç†æ¡†æ¶ï¼Œå®ƒå®æ—¶åœ°å¤„ç†æ•°æ®ï¼Œæ‰€ä»¥å®ƒä¼šåœ¨æ¯ä¸€æ¬¡é‡åˆ°ä¸€ä¸ªæ–°çš„å•è¯æ—¶å°±æ›´æ–°å’Œè¾“å‡ºè®¡æ•°ã€‚å› æ­¤ï¼Œæ¯å½“ 'Hello' å‡ºç°æ—¶ï¼Œéƒ½ä¼šæ›´æ–°å’Œè¾“å‡ºå…¶è®¡æ•°ã€‚

å¯¹äºè¿™ä¸ªä¾‹å­:

-   é¦–å…ˆé‡åˆ° 'Hello' å’Œ 'World'ï¼Œæ‰€ä»¥è¾“å‡º (hello,1) å’Œ (world,1)ã€‚
-   ç„¶åå†æ¬¡é‡åˆ° 'Hello' å’Œç¬¬ä¸€æ¬¡é‡åˆ° 'Flink'ï¼Œæ‰€ä»¥è¾“å‡º (hello,2) å’Œ (flink,1)ã€‚
-   æœ€åå†æ¬¡é‡åˆ° 'Hello' å’Œç¬¬ä¸€æ¬¡é‡åˆ° 'Java'ï¼Œæ‰€ä»¥è¾“å‡º (hello,3) å’Œ (java,1)ã€‚

è¿™æ®µä»£ç å·²åœ¨æœ¬åœ°è¿è¡Œå’Œæµ‹è¯•è¿‡ï¼Œä¸”ç›¸å…³éƒ¨åˆ†å·²æ·»åŠ æ³¨é‡Šï¼Œå¤§å®¶å¯ä»¥å®é™…è¿è¡Œæ„Ÿå—ä¸€ä¸‹ã€‚

## å¹¶è¡Œåº¦

**ç‰¹å®šç®—å­çš„å­ä»»åŠ¡ï¼ˆsubtaskï¼‰çš„ä¸ªæ•°ç§°ä¹‹ä¸ºå¹¶è¡Œåº¦ï¼ˆparallelï¼‰ï¼Œå¹¶è¡Œåº¦æ˜¯å‡ ï¼Œè¿™ä¸ªtaskå†…éƒ¨å°±æœ‰å‡ ä¸ªsubtask**

æ€æ ·å®ç°ç®—å­å¹¶è¡Œå‘¢ï¼Ÿå…¶å®ä¹Ÿå¾ˆç®€å•ï¼Œæˆ‘ä»¬æŠŠä¸€ä¸ªç®—å­æ“ä½œï¼Œâ€œå¤åˆ¶â€å¤šä»½åˆ°å¤šä¸ªèŠ‚ç‚¹ï¼Œæ•°æ®æ¥äº†ä¹‹åå°±å¯ä»¥åˆ°å…¶ä¸­ä»»æ„ä¸€ä¸ªæ‰§è¡Œã€‚è¿™æ ·ä¸€æ¥ï¼Œä¸€ä¸ªç®—å­ä»»åŠ¡å°±è¢«æ‹†åˆ†æˆäº†å¤šä¸ªå¹¶è¡Œçš„â€œå­ä»»åŠ¡â€ï¼ˆsubtasksï¼‰ï¼Œå†å°†å®ƒä»¬åˆ†å‘åˆ°ä¸åŒèŠ‚ç‚¹ï¼Œå°±çœŸæ­£å®ç°äº†å¹¶è¡Œè®¡ç®—ã€‚

**æ•´ä¸ªæµå¤„ç†ç¨‹åºçš„å¹¶è¡Œåº¦ï¼Œç†è®ºä¸Šæ˜¯æ‰€æœ‰ç®—å­å¹¶è¡Œåº¦ä¸­æœ€å¤§çš„é‚£ä¸ªï¼Œè¿™ä»£è¡¨äº†è¿è¡Œç¨‹åºéœ€è¦çš„ slot æ•°é‡**

å¦‚æœæˆ‘ä»¬å°†ä¸Šé¢WordCountç¨‹åºçš„å¹¶è¡Œåº¦è®¾ç½®ä¸º3

```scss
env.setParallelism(3);
```

å°±ä¼šçœ‹åˆ°å¦‚ä¸‹è¾“å‡ºï¼š

```scss
2> (world,1) 3> (flink,1) 1> (hello,1) 1> (hello,2) 1> (java,1) 1> (hello,3)
```

å‰é¢çš„æ•°å­—ä»£è¡¨çº¿ç¨‹ï¼ŒFlinkä¼šå°†ç›¸åŒçš„ key åˆ†é…åˆ°ä¸åŒçš„ slot è¿›è¡Œå¤„ç†ã€‚

### å¹¶è¡Œåº¦è®¾ç½®

åœ¨ Flink ä¸­ï¼Œå¯ä»¥ç”¨ä¸åŒçš„æ–¹æ³•æ¥è®¾ç½®å¹¶è¡Œåº¦ï¼Œå®ƒä»¬çš„æœ‰æ•ˆèŒƒå›´å’Œä¼˜å…ˆçº§åˆ«ä¹Ÿæ˜¯ä¸åŒçš„ã€‚

**ä»£ç ä¸­è®¾ç½®**

-   æˆ‘ä»¬åœ¨ä»£ç ä¸­ï¼Œå¯ä»¥å¾ˆç®€å•åœ°åœ¨ç®—å­åè·Ÿç€è°ƒç”¨ `setParallelism()`æ–¹æ³•ï¼Œæ¥è®¾ç½®å½“å‰ç®—å­çš„å¹¶è¡Œåº¦ï¼š `stream.map(word -> Tuple2.of(word, 1L)).setParallelism(2);`è¿™ç§æ–¹å¼è®¾ç½®çš„å¹¶è¡Œåº¦ï¼Œåªé’ˆå¯¹å½“å‰ç®—å­æœ‰æ•ˆã€‚
-   æˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥è°ƒç”¨æ‰§è¡Œç¯å¢ƒçš„ `setParallelism()`æ–¹æ³•ï¼Œå…¨å±€è®¾å®šå¹¶è¡Œåº¦ï¼š`env.setParallelism(2);`è¿™æ ·ä»£ç ä¸­æ‰€æœ‰ç®—å­ï¼Œé»˜è®¤çš„å¹¶è¡Œåº¦å°±éƒ½ä¸º2äº†ã€‚

**æäº¤åº”ç”¨æ—¶è®¾ç½®**

åœ¨ä½¿ç”¨ flink run å‘½ä»¤æäº¤åº”ç”¨æ—¶ï¼Œå¯ä»¥å¢åŠ  `-p` å‚æ•°æ¥æŒ‡å®šå½“å‰åº”ç”¨ç¨‹åºæ‰§è¡Œçš„å¹¶è¡Œåº¦ï¼Œå®ƒçš„ä½œç”¨ç±»ä¼¼äºæ‰§è¡Œç¯å¢ƒçš„å…¨å±€è®¾ç½®ã€‚å¦‚æœæˆ‘ä»¬ç›´æ¥åœ¨ Web UI ä¸Šæäº¤ä½œä¸šï¼Œä¹Ÿå¯ä»¥åœ¨å¯¹åº”è¾“å…¥æ¡†ä¸­ç›´æ¥æ·»åŠ å¹¶è¡Œåº¦ã€‚

**é…ç½®æ–‡ä»¶ä¸­è®¾ç½®**

æˆ‘ä»¬è¿˜å¯ä»¥ç›´æ¥åœ¨é›†ç¾¤çš„é…ç½®æ–‡ä»¶ flink-conf.yaml ä¸­ç›´æ¥æ›´æ”¹é»˜è®¤å¹¶è¡Œåº¦ï¼š`parallelism.default: 2`ï¼ˆåˆå§‹å€¼ä¸º 1ï¼‰

è¿™ä¸ªè®¾ç½®å¯¹äºæ•´ä¸ªé›†ç¾¤ä¸Šæäº¤çš„æ‰€æœ‰ä½œä¸šæœ‰æ•ˆã€‚

### å¹¶è¡Œåº¦ç”Ÿæ•ˆä¼˜å…ˆçº§

1.  å¯¹äºä¸€ä¸ªç®—å­ï¼Œé¦–å…ˆçœ‹åœ¨ä»£ç ä¸­æ˜¯å¦å•ç‹¬æŒ‡å®šäº†å®ƒçš„å¹¶è¡Œåº¦ï¼Œè¿™ä¸ªç‰¹å®šçš„è®¾ç½®ä¼˜å…ˆçº§æœ€é«˜ï¼Œä¼šè¦†ç›–åé¢æ‰€æœ‰çš„è®¾ç½®ã€‚
2.  å¦‚æœæ²¡æœ‰å•ç‹¬è®¾ç½®ï¼Œé‚£ä¹ˆé‡‡ç”¨å½“å‰ä»£ç ä¸­æ‰§è¡Œç¯å¢ƒå…¨å±€è®¾ç½®çš„å¹¶è¡Œåº¦ã€‚
3.  å¦‚æœä»£ç ä¸­å®Œå…¨æ²¡æœ‰è®¾ç½®ï¼Œé‚£ä¹ˆé‡‡ç”¨æäº¤æ—¶`-p` å‚æ•°æŒ‡å®šçš„å¹¶è¡Œåº¦ã€‚
4.  å¦‚æœæäº¤æ—¶ä¹ŸæœªæŒ‡å®š`-p` å‚æ•°ï¼Œé‚£ä¹ˆé‡‡ç”¨é›†ç¾¤é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å¹¶è¡Œåº¦ã€‚

**è¿™é‡Œéœ€è¦è¯´æ˜çš„æ˜¯ï¼Œç®—å­çš„å¹¶è¡Œåº¦æœ‰æ—¶ä¼šå—åˆ°è‡ªèº«å…·ä½“å®ç°çš„å½±å“ã€‚æ¯”å¦‚è¯»å– socket æ–‡æœ¬æµçš„ç®—å­ socketTextStreamï¼Œå®ƒæœ¬èº«å°±æ˜¯éå¹¶è¡Œçš„ Source ç®—å­ï¼Œæ‰€ä»¥æ— è®ºæ€ä¹ˆè®¾ç½®ï¼Œå®ƒåœ¨è¿è¡Œæ—¶çš„å¹¶è¡Œåº¦éƒ½æ˜¯ 1**

## Task

åœ¨ Flink ä¸­ï¼ŒTask æ˜¯ä¸€ä¸ªé˜¶æ®µå¤šä¸ªåŠŸèƒ½ç›¸åŒ subTask çš„é›†åˆï¼ŒFlink ä¼šå°½å¯èƒ½åœ°å°† operator çš„ subtask é“¾æ¥ï¼ˆchainï¼‰åœ¨ä¸€èµ·å½¢æˆ taskã€‚æ¯ä¸ª task åœ¨ä¸€ä¸ªçº¿ç¨‹ä¸­æ‰§è¡Œã€‚å°† operators é“¾æ¥æˆ task æ˜¯éå¸¸æœ‰æ•ˆçš„ä¼˜åŒ–ï¼šå®ƒèƒ½å‡å°‘çº¿ç¨‹ä¹‹é—´çš„åˆ‡æ¢ï¼Œå‡å°‘æ¶ˆæ¯çš„åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼Œå‡å°‘æ•°æ®åœ¨ç¼“å†²åŒºçš„äº¤æ¢ï¼Œå‡å°‘äº†å»¶è¿Ÿçš„åŒæ—¶æé«˜æ•´ä½“çš„ååé‡ã€‚

**è¦æ˜¯ä¹‹å‰å­¦è¿‡Sparkï¼Œè¿™é‡Œå¯ä»¥ç”¨Sparkçš„æ€æƒ³æ¥çœ‹ï¼ŒFlinkçš„Taskå°±å¥½æ¯”Sparkä¸­çš„Stageï¼Œè€Œæˆ‘ä»¬çŸ¥é“Sparkçš„Stageæ˜¯æ ¹æ®å®½ä¾èµ–æ¥æ‹†åˆ†çš„ã€‚æ‰€ä»¥æˆ‘ä»¬ä¹Ÿå¯ä»¥è®¤ä¸ºFlinkçš„Taskä¹Ÿæ˜¯æ ¹æ®å®½ä¾èµ–æ‹†åˆ†çš„ï¼ˆå°½ç®¡Flinkä¸­å¹¶æ²¡æœ‰å®½ä¾èµ–çš„æ¦‚å¿µï¼‰ï¼Œè¿™æ ·ä¼šæ›´å¥½ç†è§£**

å¦‚ä¸‹å›¾ï¼š

![[Blog/Picture/7441ecf3dced88d1a78a78ea11f20e0d_MD5.png]]

## Operator Chainï¼ˆç®—å­é“¾)

åœ¨Flinkä¸­ï¼Œä¸ºäº†åˆ†å¸ƒå¼æ‰§è¡Œï¼ŒFlinkä¼šå°†ç®—å­å­ä»»åŠ¡é“¾æ¥åœ¨ä¸€èµ·å½¢æˆä»»åŠ¡ã€‚æ¯ä¸ªä»»åŠ¡ç”±ä¸€ä¸ªçº¿ç¨‹æ‰§è¡Œã€‚å°†ç®—å­é“¾æ¥åœ¨ä¸€èµ·å½¢æˆä»»åŠ¡æ˜¯ä¸€ç§æœ‰ç”¨çš„ä¼˜åŒ–ï¼š**å®ƒå‡å°‘äº†çº¿ç¨‹é—´åˆ‡æ¢å’Œç¼“å†²çš„å¼€é”€ï¼Œå¹¶å¢åŠ äº†æ•´ä½“ååé‡ï¼ŒåŒæ—¶é™ä½äº†å»¶è¿Ÿ**

ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„Flinkæµå¤„ç†ç¨‹åºï¼Œå®ƒä»ä¸€ä¸ªæºè¯»å–æ•°æ®ï¼Œç„¶ååº”ç”¨`map`å’Œ`filter`æ“ä½œï¼Œæœ€åå°†ç»“æœå†™å…¥åˆ°ä¸€ä¸ªæ¥æ”¶å™¨ã€‚è¿™ä¸ªç¨‹åºå¯èƒ½çœ‹èµ·æ¥åƒè¿™æ ·ï¼š

```undefined
DataStream<String> data = env.addSource(new CustomSource()); data.map(new MapFunction<String, String>() { @Override public String map(String value) throws Exception { return value.toUpperCase(); } }) .filter(new FilterFunction<String>() { @Override public boolean filter(String value) throws Exception { return value.startsWith("A"); } }) .addSink(new CustomSink());
```

**åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œ`map`å’Œ`filter`æ“ä½œå¯ä»¥è¢«é“¾æ¥åœ¨ä¸€èµ·å½¢æˆä¸€ä¸ªä»»åŠ¡ï¼Œè¢«ä¼˜åŒ–ä¸ºç®—å­é“¾ï¼Œè¿™æ„å‘³ç€å®ƒä»¬å°†åœ¨åŒä¸€ä¸ªçº¿ç¨‹ä¸­æ‰§è¡Œï¼Œè€Œä¸æ˜¯åœ¨ä¸åŒçš„çº¿ç¨‹ä¸­æ‰§è¡Œå¹¶é€šè¿‡ç½‘ç»œè¿›è¡Œæ•°æ®ä¼ è¾“**

## Task Slots

Task Slotså³æ˜¯ä»»åŠ¡æ§½ï¼Œslot åœ¨ Flink é‡Œé¢å¯ä»¥è®¤ä¸ºæ˜¯èµ„æºç»„ï¼ŒFlink å°†æ¯ä¸ªä»»åŠ¡åˆ†æˆå­ä»»åŠ¡å¹¶ä¸”å°†è¿™äº›å­ä»»åŠ¡åˆ†é…åˆ° slot æ¥å¹¶è¡Œæ‰§è¡Œç¨‹åºï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é›†ç¾¤çš„é…ç½®æ–‡ä»¶æ¥è®¾å®š TaskManager çš„ slot æ•°é‡ï¼š `taskmanager.numberOfTaskSlots : 8`ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœ Task Manager æœ‰2ä¸ª slotï¼Œé‚£ä¹ˆå®ƒå°†ä¸ºæ¯ä¸ª slot åˆ†é… 50ï¼… çš„å†…å­˜ã€‚ å¯ä»¥åœ¨ä¸€ä¸ª slot ä¸­è¿è¡Œä¸€ä¸ªæˆ–å¤šä¸ªçº¿ç¨‹ã€‚ åŒä¸€ slot ä¸­çš„çº¿ç¨‹å…±äº«ç›¸åŒçš„ JVMã€‚

**éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œslot ç›®å‰ä»…ä»…ç”¨æ¥éš”ç¦»å†…å­˜ï¼Œä¸ä¼šæ¶‰åŠ CPU çš„éš”ç¦»ã€‚åœ¨å…·ä½“åº”ç”¨æ—¶ï¼Œå¯ä»¥å°† slot æ•°é‡é…ç½®ä¸ºæœºå™¨çš„ CPU æ ¸å¿ƒæ•°ï¼Œå°½é‡é¿å…ä¸åŒä»»åŠ¡ä¹‹é—´å¯¹ CPU çš„ç«äº‰ã€‚è¿™ä¹Ÿæ˜¯å¼€å‘ç¯å¢ƒé»˜è®¤å¹¶è¡Œåº¦è®¾ä¸ºæœºå™¨ CPU æ•°é‡çš„åŸå› **

### åˆ†å‘è§„åˆ™

-   **ä¸åŒçš„Taskä¸‹çš„subtaskè¦åˆ†å‘åˆ°åŒä¸€ä¸ªTaskSlotä¸­ï¼Œé™ä½æ•°æ®ä¼ è¾“ã€æé«˜æ‰§è¡Œæ•ˆç‡**
-   **ç›¸åŒçš„Taskä¸‹çš„subtaskè¦åˆ†å‘åˆ°ä¸åŒçš„TaskSlot**

### Slotå…±äº«ç»„

å¦‚æœå¸Œæœ›æŸä¸ªç®—å­å¯¹åº”çš„ä»»åŠ¡å®Œå…¨ç‹¬å ä¸€ä¸ª slotï¼Œæˆ–è€…åªæœ‰æŸä¸€éƒ¨åˆ†ç®—å­å…±äº« slotï¼Œåœ¨Flinkä¸­ï¼Œå¯ä»¥é€šè¿‡åœ¨ä»£ç ä¸­ä½¿ç”¨`slotSharingGroup`æ–¹æ³•æ¥è®¾ç½®slotå…±äº«ç»„ã€‚

Flinkä¼šå°†å…·æœ‰ç›¸åŒslotå…±äº«ç»„çš„æ“ä½œæ”¾å…¥åŒä¸€ä¸ªslotä¸­ï¼ŒåŒæ—¶ä¿æŒä¸å…·æœ‰slotå…±äº«ç»„çš„æ“ä½œåœ¨å…¶ä»–slotä¸­ã€‚è¿™å¯ä»¥ç”¨æ¥éš”ç¦»slotã€‚

ä¾‹å¦‚ï¼Œä½ å¯ä»¥è¿™æ ·è®¾ç½®ï¼š

```undefined
dataStream.map(...).slotSharingGroup("group1");
```

é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ“ä½œéƒ½è¢«åˆ†é…ç›¸åŒçš„SlotSharingGroupã€‚

è¿™æ ·ï¼Œåªæœ‰å±äºåŒä¸€ä¸ª slot å…±äº«ç»„çš„å­ä»»åŠ¡ï¼Œæ‰ä¼šå¼€å¯ slot å…±äº«ï¼Œä¸åŒç»„ä¹‹é—´çš„ä»»åŠ¡æ˜¯å®Œå…¨éš”ç¦»çš„ï¼Œå¿…é¡»åˆ†é…åˆ°ä¸åŒçš„ slot ä¸Šã€‚

### å¹¶è¡Œåº¦å’ŒSlotsè§£é‡Š

å¬äº†ä¸Šé¢å¹¶è¡Œåº¦å’ŒSlotsçš„ç†è®ºï¼Œå¯èƒ½è¿˜æ˜¯æœ‰ç‚¹ç–‘æƒ‘ï¼Œä¸‹é¢é€šè¿‡ä¾‹å­è§£é‡Šè¯´æ˜ä¸‹ï¼š

å‡è®¾ä¸€å…±æœ‰3ä¸ªTaskManagerï¼Œæ¯ä¸€ä¸ªTaskManagerä¸­çš„slotæ•°é‡è®¾ç½®ä¸º3ä¸ªï¼Œé‚£ä¹ˆä¸€å…±æœ‰9ä¸ªtask slotï¼Œè¡¨ç¤ºæœ€å¤šèƒ½å¹¶è¡Œæ‰§è¡Œ9ä¸ªä»»åŠ¡ã€‚

å‡è®¾æˆ‘ä»¬å†™äº†ä¸€ä¸ªWordCountç¨‹åºï¼Œæœ‰å››ä¸ªè½¬æ¢ç®—å­ï¼š**source â€”> flatMap â€”> reduce â€”> sink**

å½“æ‰€æœ‰ç®—å­å¹¶è¡Œåº¦ç›¸åŒæ—¶ï¼Œå¾ˆå®¹æ˜“çœ‹å‡ºsourceå’ŒflatMapå¯ä»¥ä¼˜åŒ–åˆå¹¶ç®—å­é“¾ï¼Œäºæ˜¯æœ€ç»ˆæœ‰ä¸‰ä¸ªä»»åŠ¡èŠ‚ç‚¹ï¼šsource & flatMapï¼Œreduce å’Œsinkã€‚  
å¦‚æœæˆ‘ä»¬æ²¡æœ‰ä»»ä½•å¹¶è¡Œåº¦è®¾ç½®ï¼Œè€Œé…ç½®æ–‡ä»¶ä¸­é»˜è®¤`parallelism.defaultï¼š1`ï¼Œé‚£ä¹ˆé»˜è®¤å¹¶è¡Œåº¦ä¸º1ï¼Œæ€»å…±æœ‰3ä¸ªä»»åŠ¡ã€‚**ç”±äºä¸åŒç®—å­çš„ä»»åŠ¡å¯ä»¥å…±äº«ä»»åŠ¡æ§½ï¼Œæ‰€ä»¥æœ€ç»ˆå ç”¨çš„slotåªæœ‰1ä¸ªã€‚9ä¸ªslotåªç”¨äº†1ä¸ªï¼Œæœ‰8ä¸ªç©ºé—²**

å¦‚å›¾æ‰€ç¤ºï¼š

![[Blog/Picture/d22f66c9e55421b14b6c8d0ab234e055_MD5.png]]

æˆ‘ä»¬å¯ä»¥ç›´æ¥æŠŠå¹¶è¡Œåº¦è®¾ç½®ä¸º 9ï¼Œè¿™æ ·æ‰€æœ‰ 3\*9=27 ä¸ªä»»åŠ¡å°±ä¼šå®Œå…¨å ç”¨ 9 ä¸ª slotã€‚è¿™æ˜¯å½“å‰é›†ç¾¤èµ„æºä¸‹èƒ½æ‰§è¡Œçš„æœ€å¤§å¹¶è¡Œåº¦ï¼Œè®¡ç®—èµ„æºå¾—åˆ°äº†å……åˆ†çš„åˆ©ç”¨ã€‚

å¦å¤–å†è€ƒè™‘å¯¹äºæŸä¸ªç®—å­å•ç‹¬è®¾ç½®å¹¶è¡Œåº¦çš„åœºæ™¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è€ƒè™‘åˆ°è¾“å‡ºå¯èƒ½æ˜¯å†™å…¥æ–‡ä»¶ï¼Œé‚£ä¼šå¸Œæœ›ä¸è¦å¹¶è¡Œå†™å…¥å¤šä¸ªæ–‡ä»¶ï¼Œå°±éœ€è¦è®¾ç½® sink ç®—å­çš„å¹¶è¡Œåº¦ä¸º 1ã€‚è¿™æ—¶å…¶ä»–çš„ç®—å­å¹¶è¡Œåº¦ä¾ç„¶ä¸º 9ï¼Œæ‰€ä»¥æ€»å…±ä¼šæœ‰ 19 ä¸ªå­ä»»åŠ¡ã€‚

æ ¹æ® slot å…±äº«çš„åŸåˆ™ï¼Œå®ƒä»¬æœ€ç»ˆè¿˜æ˜¯ä¼šå ç”¨å…¨éƒ¨çš„ 9 ä¸ª slotï¼Œè€Œ sink ä»»åŠ¡åªåœ¨å…¶ä¸­ä¸€ä¸ª slot ä¸Šæ‰§è¡Œï¼Œé€šè¿‡è¿™ä¸ªä¾‹å­ä¹Ÿå¯ä»¥æ˜ç¡®åœ°çœ‹åˆ°ï¼Œ**æ•´ä¸ªæµå¤„ç†ç¨‹åºçš„å¹¶è¡Œåº¦ï¼Œå°±åº”è¯¥æ˜¯æ‰€æœ‰ç®—å­å¹¶è¡Œåº¦ä¸­æœ€å¤§çš„é‚£ä¸ªï¼Œè¿™ä»£è¡¨äº†è¿è¡Œç¨‹åºéœ€è¦çš„ slot æ•°é‡**

## DataSourceæ•°æ®æº

Flinkå†…åµŒæ”¯æŒçš„æ•°æ®æºéå¸¸å¤šï¼Œæ¯”å¦‚HDFSã€Socketã€Kafkaã€Collectionsã€‚Flinkä¹Ÿæä¾›äº†addSourceæ–¹å¼ï¼Œå¯ä»¥è‡ªå®šä¹‰æ•°æ®æºï¼Œä¸‹é¢ä»‹ç»ä¸€äº›å¸¸ç”¨çš„æ•°æ®æºã€‚

### File Source

-   é€šè¿‡è¯»å–æœ¬åœ°ã€HDFSæ–‡ä»¶åˆ›å»ºä¸€ä¸ªæ•°æ®æºã€‚

å¦‚æœè¯»å–çš„æ˜¯HDFSä¸Šçš„æ–‡ä»¶ï¼Œé‚£ä¹ˆéœ€è¦å¯¼å…¥Hadoopä¾èµ–

```xml
<dependency> <groupId>org.apache.hadoop</groupId> <artifactId>hadoop-client</artifactId> <version>3.3.1</version> </dependency>
```

ä»£ç ç¤ºä¾‹ï¼šæ¯éš”10så»è¯»å–HDFSæŒ‡å®šç›®å½•ä¸‹çš„æ–°å¢æ–‡ä»¶å†…å®¹ï¼Œå¹¶ä¸”è¿›è¡ŒWordCountã€‚

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); String filePath = "hdfs://node01:9000/flink/data/"; FileInputFormat<String> textInputFormat = new TextInputFormat(new Path(filePath)); //PROCESS_CONTINUOUSLYæ¨¡å¼æ—¶ï¼ŒFlinkä¼šæŒç»­ç›‘è§†ç»™å®šçš„è·¯å¾„ï¼Œå¹¶åœ¨å‘ç°æ–°æ•°æ®æ—¶å°†å…¶å¼•å…¥æµä¸­è¿›è¡Œå¤„ç†ã€‚ DataStream<String> textStream = env.readFile(textInputFormat, filePath, FileProcessingMode.PROCESS_CONTINUOUSLY, 10000); DataStream<Tuple2<String, Integer>> result = textStream .flatMap(new WordSplitter()) .map(new WordMapper()) .keyBy(0) .sum(1); result.print(); env.execute(); } public static class WordSplitter implements FlatMapFunction<String, Tuple2<String, Integer>> { @Override public void flatMap(String value, Collector<Tuple2<String, Integer>> out) { String[] words = value.split(" "); for (String word : words) { out.collect(new Tuple2<>(word, 1)); } } } public static class WordMapper implements MapFunction<Tuple2<String, Integer>, Tuple2<String, Integer>> { @Override public Tuple2<String, Integer> map(Tuple2<String, Integer> wordCountTuple) { //f0, f1 ç­‰æ˜¯ç”¨æ¥è®¿é—®å…ƒç»„ä¸­çš„å…ƒç´ çš„å­—æ®µã€‚Tuple2<String, Integer> è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå¤§å°ä¸º 2 çš„å…ƒç»„ï¼Œå…¶ä¸­ f0 æ˜¯ String ç±»å‹ï¼Œf1 æ˜¯ Integer ç±»å‹ã€‚ // åœ¨ä»£ç ä¸­ï¼ŒwordCountTuple.f0 è¡¨ç¤ºçš„å°±æ˜¯å•è¯ï¼ˆå³Stringç±»å‹çš„å€¼ï¼‰ï¼ŒwordCountTuple.f1 åˆ™è¡¨ç¤ºçš„æ˜¯è¿™ä¸ªå•è¯çš„è®¡æ•°ï¼ˆå³ Integer ç±»å‹çš„å€¼ï¼‰ã€‚ return new Tuple2<>(wordCountTuple.f0, wordCountTuple.f1); } }
```

### Collection Source

åŸºäºæœ¬åœ°é›†åˆçš„æ•°æ®æºï¼Œä¸€èˆ¬ç”¨äºæµ‹è¯•åœºæ™¯ï¼Œå¯¹äºçº¿ä¸Šç¯å¢ƒæ²¡æœ‰å¤ªå¤§æ„ä¹‰ã€‚

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); List<String> data = Arrays.asList("hello word flink","hello java flink"); DataStream<String> text = env.fromCollection(data); DataStream<Tuple2<String, Integer>> counts = text .flatMap(new Tokenizer()) .keyBy(0) .sum(1); counts.print(); env.execute("WordCount Example"); }
```

### Socket Source

æ¥å—Socket Serverä¸­çš„æ•°æ®ï¼š

```java
public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // è¿æ¥ socket è·å–è¾“å…¥æ•°æ® DataStream<String> text = env.socketTextStream("localhost", 9999); // è§£ææ•°æ®ã€å¯¹æ•°æ®è¿›è¡Œåˆ†ç»„ã€çª—å£å¤„ç†å’Œèšåˆè®¡ç®— DataStream<Tuple2<String, Integer>> wordCount = text.flatMap(new Tokenizer()) .keyBy(0) .sum(1); wordCount.print(); env.execute("WordCount from Socket TextStream Example"); }
```

### Kafka Source

Flinkæƒ³è¦æ¥å—Kafkaä¸­çš„æ•°æ®ï¼Œé¦–å…ˆè¦é…ç½®flinkä¸kafkaçš„è¿æ¥å™¨ä¾èµ–ã€‚

Mavenä¾èµ–ï¼š

```xml
<!-- https://mvnrepository.com/artifact/org.apache.flink/flink-connector-kafka --> <dependency> <groupId>org.apache.flink</groupId> <artifactId>flink-connector-kafka_2.12</artifactId> <version>1.13.6</version> </dependency>
```

ç¤ºä¾‹ä»£ç ï¼š

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // è®¾ç½®Kafkaçš„ç›¸å…³å‚æ•°å¹¶ä»Kafkaä¸­è¯»å–æ•°æ® Properties properties = new Properties(); properties.setProperty("bootstrap.servers", "localhost:9092"); properties.setProperty("group.id", "test"); FlinkKafkaConsumer<String> flinkKafkaConsumer = new FlinkKafkaConsumer<>("topic_name", new SimpleStringSchema(), properties); DataStream<String> stream = env.addSource(flinkKafkaConsumer); // å¯¹æ¥æ”¶çš„æ¯ä¸€è¡Œæ•°æ®è¿›è¡Œå¤„ç†ï¼Œåˆ†å‰²å‡ºæ¯ä¸ªå•è¯å¹¶åˆå§‹åŒ–å…¶æ•°é‡ä¸º1 DataStream<Tuple2<String, Integer>> words = stream.flatMap(new Tokenizer()); DataStream<Tuple2<String, Integer>> wordCounts = words.keyBy(0).sum(1); wordCounts.print().setParallelism(1); env.execute("WordCountFromKafka"); }
```

## Transformations

Transformationsç®—å­å¯ä»¥å°†ä¸€ä¸ªæˆ–è€…å¤šä¸ªç®—å­è½¬æ¢æˆä¸€ä¸ªæ–°çš„æ•°æ®æµï¼Œä½¿ç”¨Transformationsç®—å­ç»„åˆå¯ä»¥å¤„ç†å¤æ‚çš„ä¸šåŠ¡å¤„ç†ã€‚

### Map

DataStream â†’ DataStream

éå†æ•°æ®æµä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ ï¼Œäº§ç”Ÿä¸€ä¸ªæ–°çš„å…ƒç´ ã€‚

### FlatMap

DataStream â†’ DataStream

éå†æ•°æ®æµä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ ï¼Œäº§ç”ŸNä¸ªå…ƒç´  N=0ï¼Œ1ï¼Œ2......ã€‚

### Filter

DataStream â†’ DataStream

è¿‡æ»¤ç®—å­ï¼Œæ ¹æ®æ•°æ®æµçš„å…ƒç´ è®¡ç®—å‡ºä¸€ä¸ªbooleanç±»å‹çš„å€¼ï¼Œtrueä»£è¡¨ä¿ç•™ï¼Œfalseä»£è¡¨è¿‡æ»¤æ‰ã€‚

### KeyBy

DataStream â†’ KeyedStream

æ ¹æ®æ•°æ®æµä¸­æŒ‡å®šçš„å­—æ®µæ¥åˆ†åŒºï¼Œç›¸åŒæŒ‡å®šå­—æ®µå€¼çš„æ•°æ®ä¸€å®šæ˜¯åœ¨åŒä¸€ä¸ªåˆ†åŒºä¸­ï¼Œå†…éƒ¨åˆ†åŒºä½¿ç”¨çš„æ˜¯HashPartitionerã€‚

æŒ‡å®šåˆ†åŒºå­—æ®µçš„æ–¹å¼æœ‰ä¸‰ç§ï¼š

-   æ ¹æ®ç´¢å¼•å·æŒ‡å®šã€‚
    
-   é€šè¿‡åŒ¿åå‡½æ•°æ¥æŒ‡å®šã€‚
    
-   é€šè¿‡å®ç°KeySelectoræ¥å£ æŒ‡å®šåˆ†åŒºå­—æ®µã€‚
    

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStreamSource<Long> stream = env.fromSequence(1, 100); stream.map((MapFunction<Long, Tuple2<Long, Integer>>) (Long x) -> new Tuple2<>(x % 3, 1), TypeInformation.of(new TypeHint<Tuple2<Long, Integer>>() {})) //æ ¹æ®ç´¢å¼•å·æ¥æŒ‡å®šåˆ†åŒºå­—æ®µï¼š.keyBy(0) //é€šè¿‡ä¼ å…¥åŒ¿åå‡½æ•° æŒ‡å®šåˆ†åŒºå­—æ®µï¼š.keyBy(x=>x._1) //é€šè¿‡å®ç°KeySelectoræ¥å£ æŒ‡å®šåˆ†åŒºå­—æ®µ .keyBy((KeySelector<Tuple2<Long, Integer>, Long>) (Tuple2<Long, Integer> value) -> value.f0, BasicTypeInfo.LONG_TYPE_INFO) .sum(1).print(); env.execute("Flink Job"); }
```

### Reduce

é€‚ç”¨äºKeyedStream

KeyedStreamï¼šæ ¹æ®keyåˆ†ç»„ â†’ DataStream

**æ³¨æ„ï¼Œreduceæ˜¯åŸºäºåˆ†åŒºåçš„æµå¯¹è±¡è¿›è¡Œèšåˆï¼Œä¹Ÿå°±æ˜¯è¯´ï¼ŒDataStreamç±»å‹çš„å¯¹è±¡æ— æ³•è°ƒç”¨reduceæ–¹æ³•**

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Tuple2<String, Integer>> dataStream = env.fromElements( new Tuple2<>("apple", 3), new Tuple2<>("banana", 1), new Tuple2<>("apple", 5), new Tuple2<>("banana", 2), new Tuple2<>("apple", 4) ); // ä½¿ç”¨reduceæ“ä½œï¼Œå°†inputä¸­çš„æ‰€æœ‰å…ƒç´ åˆå¹¶åˆ°ä¸€èµ· DataStream<Tuple2<String, Integer>> result = dataStream .keyBy(0) .reduce((ReduceFunction<Tuple2<String, Integer>>) (value1, value2) -> new Tuple2<>(value1.f0, value1.f1 + value2.f1)); result.print(); env.execute(); }
```

### Aggregations

KeyedStream â†’ DataStream

Aggregationsä»£è¡¨çš„æ˜¯ä¸€ç±»èšåˆç®—å­ï¼Œä¸Šé¢è¯´çš„reduceå°±å±äºAggregationsï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å¸¸ç”¨çš„ï¼š

-   `sum()`: è®¡ç®—æ•°å­—ç±»å‹å­—æ®µçš„æ€»å’Œã€‚
-   `min()`: è®¡ç®—æœ€å°å€¼ã€‚
-   `max()`: è®¡ç®—æœ€å¤§å€¼ã€‚
-   `count()`: è®¡æ•°å…ƒç´ ä¸ªæ•°ã€‚
-   `avg()`: è®¡ç®—å¹³å‡å€¼ã€‚

å¦å¤–ï¼ŒFlink è¿˜æ”¯æŒè‡ªå®šä¹‰èšåˆå‡½æ•°ï¼Œå³ä½¿ç”¨ `AggregateFunction` æ¥å£å®ç°æ›´å¤æ‚çš„èšåˆé€»è¾‘ã€‚

### Union çœŸåˆå¹¶

DataStream â†’ DataStream

> Union of two or more data streams creating a new stream containing all the elements from all the streams

**åˆå¹¶ä¸¤ä¸ªæˆ–è€…æ›´å¤šçš„æ•°æ®æµäº§ç”Ÿä¸€ä¸ªæ–°çš„æ•°æ®æµï¼Œè¿™ä¸ªæ–°çš„æ•°æ®æµä¸­åŒ…å«äº†æ‰€åˆå¹¶çš„æ•°æ®æµçš„å…ƒç´ **

æ³¨æ„ï¼šéœ€è¦ä¿è¯æ•°æ®æµä¸­å…ƒç´ ç±»å‹ä¸€è‡´

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Tuple2<String, Integer>> ds1 = env.fromCollection(Arrays.asList(Tuple2.of("a",1),Tuple2.of("b",2),Tuple2.of("c",3))); DataStream<Tuple2<String, Integer>> ds2 = env.fromCollection(Arrays.asList(Tuple2.of("d",4),Tuple2.of("e",5),Tuple2.of("f",6))); DataStream<Tuple2<String, Integer>> ds3 = env.fromCollection(Arrays.asList(Tuple2.of("g",7),Tuple2.of("h",8))); DataStream<Tuple2<String, Integer>> unionStream = ds1.union(ds2,ds3); unionStream.print(); env.execute(); }
```

åœ¨ Flink ä¸­ï¼ŒUnion æ“ä½œè¢«ç§°ä¸º "çœŸåˆå¹¶" æ˜¯å› ä¸ºå®ƒå°†ä¸¤ä¸ªæˆ–å¤šä¸ªæ•°æ®æµå®Œå…¨èåˆåœ¨ä¸€èµ·ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡ºåºï¼Œå¹¶ä¸”ä¸ä¼šå»é™¤é‡å¤é¡¹ã€‚è¿™ç§æ“ä½œæ–¹å¼ç±»ä¼¼äºåœ¨æ•°å­¦æ¦‚å¿µä¸­çš„é›†åˆè”åˆï¼ˆUnionï¼‰æ“ä½œï¼Œæ‰€ä»¥è¢«ç§°ä¸º "çœŸåˆå¹¶"ã€‚

è¯·æ³¨æ„ï¼Œä¸å…¶ä»–ä¸€äº›æ•°æ®å¤„ç†æ¡†æ¶ä¸­çš„ Union æ“ä½œç›¸æ¯”ï¼Œä¾‹å¦‚ Spark ä¸­çš„ Union ä¼šæ ¹æ®æŸäº›æ¡ä»¶å»é™¤é‡å¤çš„å…ƒç´ ï¼ŒFlink çš„ Union è¡Œä¸ºæ›´æ¥è¿‘äºæ•°å­¦ä¸Šçš„é›†åˆè”åˆç†è®ºã€‚

### Connect å‡åˆå¹¶

DataStream,DataStream â†’ ConnectedStreams

åˆå¹¶ä¸¤ä¸ªæ•°æ®æµå¹¶ä¸”ä¿ç•™ä¸¤ä¸ªæ•°æ®æµçš„æ•°æ®ç±»å‹ï¼Œèƒ½å¤Ÿå…±äº«ä¸¤ä¸ªæµçš„çŠ¶æ€

```java
public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<String> ds1 = env.socketTextStream("localhost", 8888); DataStream<String> ds2 = env.socketTextStream("localhost", 9999); DataStream<Tuple2<String, Integer>> wcStream1 = ds1 .flatMap(new Tokenizer()) .keyBy(value -> value.f0) .sum(1); DataStream<Tuple2<String, Integer>> wcStream2 = ds2 .flatMap(new Tokenizer()) .keyBy(value -> value.f0) .sum(1); ConnectedStreams<Tuple2<String, Integer>, Tuple2<String, Integer>> connectedStreams = wcStream1.connect(wcStream2); }
```

ä¸`union`ä¸åŒï¼Œ`connect`åªèƒ½è¿æ¥ä¸¤ä¸ªæµï¼Œå¹¶ä¸”è¿™ä¸¤ä¸ªæµçš„ç±»å‹å¯ä»¥ä¸åŒã€‚`connect`åçš„ä¸¤ä¸ªæµä¼šè¢«çœ‹ä½œæ˜¯ä¸¤ä¸ªä¸åŒçš„æµï¼Œå¯ä»¥ä½¿ç”¨`CoMap`æˆ–è€…`CoFlatMap`å‡½æ•°åˆ†åˆ«å¤„ç†è¿™ä¸¤ä¸ªæµã€‚

### CoMap, CoFlatMap

ConnectedStreams â†’ DataStream

**CoMap, CoFlatMapå¹¶ä¸æ˜¯å…·ä½“ç®—å­åå­—ï¼Œè€Œæ˜¯ä¸€ç±»æ“ä½œçš„åç§°**

-   å‡¡æ˜¯åŸºäºConnectedStreamsæ•°æ®æµåšmapéå†ï¼Œè¿™ç±»æ“ä½œå«åšCoMapã€‚
-   å‡¡æ˜¯åŸºäºConnectedStreamsæ•°æ®æµåšflatMapéå†ï¼Œè¿™ç±»æ“ä½œå«åšCoFlatMapã€‚

CoMapå®ç°ï¼š

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // åˆ›å»ºä¸¤ä¸ªä¸åŒçš„æ•°æ®æµ DataStream<Integer> nums = env.fromElements(1, 2, 3, 4, 5); DataStream<String> text = env.fromElements("a", "b", "c"); // è¿æ¥ä¸¤ä¸ªæ•°æ®æµ ConnectedStreams<Integer, String> connected = nums.connect(text); // ä½¿ç”¨ CoMap å¤„ç†è¿æ¥çš„æµ DataStream<String> result = connected.map(new CoMapFunction<Integer, String, String>() { @Override public String map1(Integer value) { return String.valueOf(value*2); } @Override public String map2(String value) { return "hello " + value; } }); result.print(); env.execute("CoMap example"); }
```

CoFlatMapå®ç°æ–¹å¼ï¼š

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Integer> nums = env.fromElements(1, 2, 3, 4, 5); DataStream<String> text = env.fromElements("a", "b", "c"); ConnectedStreams<Integer, String> connected = nums.connect(text); DataStream<String> result = connected.flatMap(new CoFlatMapFunction<Integer, String, String>() { @Override public void flatMap1(Integer value, Collector<String> out) { out.collect(String.valueOf(value*2)); out.collect(String.valueOf(value*3)); } @Override public void flatMap2(String value, Collector<String> out) { out.collect("hello " + value); out.collect("hi " + value); } }); result.print(); env.execute("CoFlatMap example"); }
```

### Split/Select

DataStream â†’ SplitStream

æ ¹æ®æ¡ä»¶å°†ä¸€ä¸ªæµåˆ†æˆå¤šä¸ªæµï¼Œç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStreamSource<Long> data = env.generateSequence(0, 10); SplitStream<Long> split = data.split((OutputSelector<Long>) value -> { List<String> output = new ArrayList<>(); if (value % 2 == 0) { output.add("even"); } else { output.add("odd"); } return output; }); split.select("odd").print(); env.execute("Flink SplitStream Example"); }
```

`select()`ç”¨äºä»SplitStreamä¸­é€‰æ‹©ä¸€ä¸ªæˆ–è€…å¤šä¸ªæ•°æ®æµã€‚

```scala
split.select("odd").print();
```

### SideOutput

**æ³¨æ„ï¼šåœ¨Flink 1.12 åŠä¹‹åçš„ç‰ˆæœ¬ä¸­ï¼ŒSplitStream å·²ç»è¢«å¼ƒç”¨å¹¶ç§»é™¤ï¼Œä¸€èˆ¬æ¨èä½¿ç”¨ Side Outputsï¼ˆä¾§è¾“å‡ºæµï¼‰æ¥æ›¿ä»£ Splitå’ŒSelect**

ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```java
private static final OutputTag<String> evenOutput = new OutputTag<String>("even"){}; private static final OutputTag<String> oddOutput = new OutputTag<String>("odd"){}; public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<String> input = env.fromElements("1", "2", "3", "4", "5"); SingleOutputStreamOperator<String> processed = input.process(new ProcessFunction<String, String>() { @Override public void processElement(String value, Context ctx, Collector<String> out){ int i = Integer.parseInt(value); if (i % 2 == 0) { ctx.output(evenOutput, value); } else { ctx.output(oddOutput, value); } } }); DataStream<String> evenStream = processed.getSideOutput(evenOutput); DataStream<String> oddStream = processed.getSideOutput(oddOutput); evenStream.print("even"); oddStream.print("odd"); env.execute("Side Output Example"); }
```

### Iterate

DataStream â†’ IterativeStream â†’ DataStream

Iterateç®—å­æä¾›äº†å¯¹æ•°æ®æµè¿­ä»£çš„æ”¯æŒ

ä¸€ä¸ªæ•°æ®é›†é€šè¿‡è¿­ä»£è¿ç®—ç¬¦è¢«åˆ’åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šâ€œåé¦ˆâ€éƒ¨åˆ†ï¼ˆfeedbackï¼‰å’Œâ€œè¾“å‡ºâ€éƒ¨åˆ†ï¼ˆoutputï¼‰ã€‚åé¦ˆéƒ¨åˆ†è¢«åé¦ˆåˆ°è¿­ä»£å¤´ï¼ˆiteration headï¼‰ï¼Œä»è€Œå½¢æˆä¸‹ä¸€æ¬¡è¿­ä»£ã€‚è¾“å‡ºéƒ¨åˆ†åˆ™æ„æˆè¯¥è¿­ä»£çš„ç»“æœï¼š

```java
public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Long> input = env.fromElements(10L); // å®šä¹‰è¿­ä»£æµï¼Œæœ€å¤§è¿­ä»£10æ¬¡ IterativeStream<Long> iteration = input.iterate(10000L); // å®šä¹‰è¿­ä»£é€»è¾‘ DataStream<Long> minusOne = iteration.map((MapFunction<Long, Long>) value -> value - 1); // å®šä¹‰åé¦ˆæµï¼ˆæ»¡è¶³æ¡ä»¶ç»§ç»­è¿­ä»£ï¼‰å’Œè¾“å‡ºæµï¼ˆä¸æ»¡è¶³æ¡ä»¶çš„ç»“æœï¼‰ DataStream<Long> stillGreaterThanZero = minusOne.filter(value -> value > 0).setParallelism(1);; DataStream<Long> lessThanZero = minusOne.filter(value -> value <= 0); // å…³é—­è¿­ä»£ï¼Œå®šä¹‰åé¦ˆæµ iteration.closeWith(stillGreaterThanZero); // æ‰“å°ç»“æœ lessThanZero.print(); env.execute("Iterative Stream Example"); }
```

### æ™®é€šå‡½æ•° & å¯Œå‡½æ•°

Apache Flink ä¸­æœ‰ä¸¤ç§ç±»å‹çš„å‡½æ•°ï¼š ã€Œ**æ™®é€šå‡½æ•°ï¼ˆRegular Functionsï¼‰**ã€å’Œ ã€Œ**å¯Œå‡½æ•°ï¼ˆRich Functionsï¼‰**ã€ã€‚ä¸»è¦åŒºåˆ«åœ¨äºå¯Œå‡½æ•°ç›¸æ¯”æ™®é€šå‡½æ•°æä¾›äº†æ›´å¤šç”Ÿå‘½å‘¨æœŸæ–¹æ³•å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

-   **æ™®é€šå‡½æ•°**ï¼šè¿™äº›å‡½æ•°åªéœ€è¦è¦†ç›–ä¸€ä¸ªæˆ–å‡ ä¸ªç‰¹å®šæ–¹æ³•ï¼Œå¦‚ `MapFunction` éœ€è¦å®ç° `map()` æ–¹æ³•ã€‚å®ƒä»¬æ²¡æœ‰ç”Ÿå‘½å‘¨æœŸæ–¹æ³•ï¼Œä¹Ÿä¸èƒ½è®¿é—®æ‰§è¡Œç¯å¢ƒçš„ä¸Šä¸‹æ–‡ã€‚
-   **å¯Œå‡½æ•°**ï¼šé™¤äº†è¦†ç›–ç‰¹å®šå‡½æ•°å¤–ï¼Œå¯Œå‡½æ•°è¿˜æä¾›äº†å¯¹ Flink API æ›´å¤šçš„æ§åˆ¶å’Œæ“ä½œï¼ŒåŒ…æ‹¬ï¼š
    -   ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼šå¯ä»¥è¦†ç›– `open()` å’Œ `close()` æ–¹æ³•ä»¥ä¾¿åœ¨å‡½æ•°å¯åŠ¨å‰å’Œå…³é—­ååšä¸€äº›è®¾ç½®æˆ–æ¸…ç†å·¥ä½œã€‚
    -   è·å–è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼šä¾‹å¦‚ï¼Œé€šè¿‡ `getRuntimeContext()` æ–¹æ³•è·å–å¹¶è¡Œä»»åŠ¡çš„ä¿¡æ¯ï¼Œå¦‚å½“å‰å­ä»»åŠ¡çš„ç´¢å¼•ç­‰ã€‚
    -   çŠ¶æ€ç®¡ç†å’Œå®¹é”™ï¼šå¯ä»¥å®šä¹‰å’Œä½¿ç”¨æ‰˜ç®¡çŠ¶æ€ï¼ˆManaged Stateï¼‰ï¼Œè¿™åœ¨æ„å»ºå®¹é”™ç³»ç»Ÿæ—¶éå¸¸é‡è¦ã€‚

ç®€è€Œè¨€ä¹‹ï¼Œå¦‚æœä½ éœ€è¦åœ¨å‡½æ•°ä¸­ä½¿ç”¨ Flink çš„é«˜çº§åŠŸèƒ½ï¼Œå¦‚çŠ¶æ€ç®¡ç†æˆ–è®¿é—®è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼Œåˆ™éœ€è¦ä½¿ç”¨å¯Œå‡½æ•°ã€‚å¦‚æœä¸éœ€è¦è¿™äº›åŠŸèƒ½ï¼Œä½¿ç”¨æ™®é€šå‡½æ•°å³å¯ã€‚

| æ™®é€šå‡½æ•°ç±» | å¯Œå‡½æ•°ç±» |
| --- | --- |
| MapFunction | RichMapFunction |
| FlatMapFunction | RichFlatMapFunction |
| FilterFunction | RichFilterFunction |
| ...... | ...... |

æ™®é€šå‡½æ•°ï¼š

```java
public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); List<String> words = Arrays.asList("hello", "world", "flink", "hello", "world"); env.fromCollection(words) .map(new MapFunction<String, Tuple2<String, Integer>>() { @Override public Tuple2<String, Integer> map(String value) { return new Tuple2<>(value, 1); } }) .keyBy(0) .sum(1) .print(); env.execute("Word Count Example"); }
```

å¯Œå‡½æ•°ï¼š

```java
public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); List<String> words = Arrays.asList("hello", "world", "flink", "hello", "world"); env.fromCollection(words) .map(new RichMapFunction<String, Tuple2<String, Integer>>() { @Override public void open(Configuration parameters) throws Exception { super.open(parameters); // å¯ä»¥åœ¨è¿™é‡Œè®¾ç½®ç›¸å…³çš„é…ç½®æˆ–è€…èµ„æºï¼Œå¦‚æ•°æ®åº“è¿æ¥ç­‰ } @Override public Tuple2<String, Integer> map(String value) throws Exception { return new Tuple2<>(value, 1); } @Override public void close() throws Exception { super.close(); // å¯ä»¥åœ¨è¿™é‡Œå®Œæˆèµ„æºçš„æ¸…ç†å·¥ä½œ } }) .keyBy(0) .sum(1) .print(); env.execute("Word Count Example"); }
```

### ProcessFunctionï¼ˆå¤„ç†å‡½æ•°ï¼‰

ProcessFunctionå±äºä½å±‚æ¬¡çš„APIï¼Œåœ¨ç±»ç»§æ‰¿å…³ç³»ä¸Šå±äºå¯Œå‡½æ•°ã€‚

æˆ‘ä»¬å‰é¢è®²çš„`map`ã€`filter`ã€`flatMap`ç­‰ç®—å­éƒ½æ˜¯åŸºäºè¿™å±‚å°è£…å‡ºæ¥çš„ã€‚

è¶Šä½å±‚æ¬¡çš„APIï¼ŒåŠŸèƒ½è¶Šå¼ºå¤§ï¼Œç”¨æˆ·èƒ½å¤Ÿè·å–çš„ä¿¡æ¯è¶Šå¤šï¼Œæ¯”å¦‚å¯ä»¥æ‹¿åˆ°å…ƒç´ çŠ¶æ€ä¿¡æ¯ã€äº‹ä»¶æ—¶é—´ã€è®¾ç½®å®šæ—¶å™¨ç­‰

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<String> dataStream = env.socketTextStream("localhost", 9999) .map(new MapFunction<String, Tuple2<String, Integer>>() { @Override public Tuple2<String, Integer> map(String value) { return new Tuple2<>(value, 1); } }) .keyBy(0) .process(new AlertFunction()); dataStream.print(); env.execute("Process Function Example"); } public static class AlertFunction extends KeyedProcessFunction<Tuple, Tuple2<String, Integer>, String> { private transient ValueState<Integer> countState; @Override public void open(Configuration config) { ValueStateDescriptor<Integer> descriptor = new ValueStateDescriptor<>( "countState", // state name TypeInformation.of(new TypeHint<Integer>() {}), // type information 0); // default value countState = getRuntimeContext().getState(descriptor); } @Override public void processElement(Tuple2<String, Integer> value, Context ctx, Collector<String> out) throws Exception { Integer currentCount = countState.value(); currentCount += 1; countState.update(currentCount); if (currentCount >= 3) { out.collect("Warning! The key '" + value.f0 + "' has been seen " + currentCount + " times."); } } }
```

è¿™é‡Œï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåä¸º`AlertFunction`çš„å¤„ç†å‡½æ•°ç±»ï¼Œå¹¶ç»§æ‰¿`KeyedProcessFunction`ã€‚å…¶ä¸­ï¼Œ`ValueState`ç”¨äºä¿å­˜çŠ¶æ€ä¿¡æ¯ï¼Œæ¯ä¸ªé”®ä¼šæœ‰å…¶è‡ªå·±çš„çŠ¶æ€å®ä¾‹ã€‚å½“è®¡æ•°è¾¾åˆ°æˆ–è¶…è¿‡ä¸‰æ¬¡æ—¶ï¼Œè¯¥ç³»ç»Ÿå°†å‘å‡ºè­¦å‘Šã€‚è¿™ä¸ªä¾‹å­ä¸»è¦å±•ç¤ºäº†å¤„ç†å‡½æ•°ä¸å…¶ä»–è¿ç®—ç¬¦ç›¸æ¯”çš„ä¸¤ä¸ªä¼˜ç‚¹ï¼šè®¿é—®é”®æ§çŠ¶æ€å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†æ–¹æ³•ï¼ˆä¾‹å¦‚`open()`ï¼‰ã€‚

æ³¨æ„ï¼šä¸Šè¿°ç¤ºä¾‹å‡è®¾ä½ å·²ç»åœ¨æœ¬åœ°çš„9999ç«¯å£ä¸Šè®¾ç½®äº†ä¸€ä¸ªsocketæœåŠ¡å™¨ï¼Œç”¨äºæµå¼ä¼ è¾“æ–‡æœ¬æ•°æ®ã€‚å¦‚æœæ²¡æœ‰ï¼Œä½ éœ€è¦æ›¿æ¢è¿™éƒ¨åˆ†ä»¥é€‚åº”ä½ çš„è¾“å…¥æºã€‚

## Sink

åœ¨Flinkä¸­ï¼Œ"Sink"æ˜¯æ•°æ®æµè®¡ç®—çš„æœ€åä¸€æ­¥ã€‚å®ƒä»£è¡¨äº†ä¸€ä¸ªè¾“å‡ºç«¯ç‚¹ï¼Œåœ¨é‚£é‡Œè®¡ç®—ç»“æœè¢«å‘é€æˆ–å­˜å‚¨ã€‚æ¢å¥è¯è¯´ï¼ŒSinkæ˜¯æ•°æ®æµå¤„ç†è¿‡ç¨‹ä¸­çš„ç»“æŸèŠ‚ç‚¹ï¼Œè´Ÿè´£å°†å¤„ç†åçš„æ•°æ®è¾“å‡ºåˆ°å¤–éƒ¨ç³»ç»Ÿï¼Œå¦‚æ•°æ®åº“ã€æ–‡ä»¶ã€æ¶ˆæ¯é˜Ÿåˆ—ç­‰ã€‚

Flinkå†…ç½®äº†å¤§é‡Sinkï¼Œå¯ä»¥å°†Flinkå¤„ç†åçš„æ•°æ®è¾“å‡ºåˆ°HDFSã€kafkaã€Redisã€ESã€MySQLç­‰ã€‚

### Redis Sink

Flinkå¤„ç†çš„æ•°æ®å¯ä»¥å­˜å‚¨åˆ°Redisä¸­ï¼Œä»¥ä¾¿å®æ—¶æŸ¥è¯¢ã€‚

é¦–å…ˆï¼Œéœ€è¦å¯¼å…¥Flinkå’ŒRedisçš„è¿æ¥å™¨ä¾èµ–ï¼š

```xml
<!-- Flink Redis connector --> <dependency> <groupId>org.apache.bahir</groupId> <artifactId>flink-connector-redis_${scala.binary.version}</artifactId> <version>1.1.0</version> </dependency>
```

ä¸‹é¢çš„ä»£ç å±•ç¤ºäº†"Word Count"(è¯é¢‘ç»Ÿè®¡)æ“ä½œï¼Œå¹¶å°†ç»“æœå­˜å‚¨åˆ°Redisæ•°æ®åº“ä¸­ï¼š

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<String> text = env.fromElements( "Hello World", "Hello Flink", "Hello Java"); DataStream<Tuple2<String, Integer>> counts = text.flatMap(new Tokenizer()) .keyBy(value -> value.f0) .sum(1); FlinkJedisPoolConfig conf = new FlinkJedisPoolConfig.Builder().setHost("localhost").build(); counts.addSink(new RedisSink<>(conf, new RedisExampleMapper())); env.execute("Word Count Example"); } public static final class Tokenizer implements FlatMapFunction<String, Tuple2<String, Integer>> { @Override public void flatMap(String value, Collector<Tuple2<String, Integer>> out) { String[] words = value.toLowerCase().split("\\W+"); for (String word : words) { if (word.length() > 0) { out.collect(new Tuple2<>(word, 1)); } } } } public static final class RedisExampleMapper implements RedisMapper<Tuple2<String, Integer>> { @Override public RedisCommandDescription getCommandDescription() { return new RedisCommandDescription(RedisCommand.HSET); } @Override public String getKeyFromData(Tuple2<String, Integer> data) { return data.f0; } @Override public String getValueFromData(Tuple2<String, Integer> data) { return data.f1.toString(); } }
```

### Kafka Sink

å¤„ç†ç»“æœå†™å…¥åˆ°kafka topicä¸­ï¼ŒFlinkä¹Ÿæ˜¯æ”¯æŒçš„ï¼Œéœ€è¦æ·»åŠ è¿æ¥å™¨ä¾èµ–ï¼Œè·Ÿè¯»å–kafkaæ•°æ®ç”¨çš„è¿æ¥å™¨ä¾èµ–ç›¸åŒï¼Œä¹‹å‰æ·»åŠ è¿‡å°±ä¸éœ€è¦å†æ·»åŠ äº†ã€‚

```xml
<dependency> <groupId>org.apache.flink</groupId> <artifactId>flink-connector-kafka_2.12</artifactId> <version>1.13.6</version> </dependency>
```

è¿˜æ˜¯ç”¨ä¸Šé¢è¯é¢‘ç»Ÿè®¡çš„ä¾‹å­ï¼š

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<String> text = env.fromElements( "Hello World", "Hello Flink", "Hello Java"); DataStream<Tuple2<String, Integer>> counts = text.flatMap(new Tokenizer()) .keyBy(value -> value.f0) .sum(1); // Define Kafka properties Properties properties = new Properties(); properties.setProperty("bootstrap.servers", "localhost:9092"); // Write the data stream to Kafka counts.map(new MapFunction<Tuple2<String,Integer>, String>() { @Override public String map(Tuple2<String,Integer> value) throws Exception { return value.f0 + "," + value.f1.toString(); } }) .addSink(new FlinkKafkaProducer<>("my-topic", new SimpleStringSchema(), properties)); env.execute("Word Count Example"); }
```

### MySQL Sink

Flinkå¤„ç†ç»“æœå†™å…¥åˆ°MySQLä¸­ï¼Œè¿™å¹¶ä¸æ˜¯Flinké»˜è®¤æ”¯æŒçš„ï¼Œéœ€è¦æ·»åŠ MySQLçš„é©±åŠ¨ä¾èµ–ï¼š

```xml
<!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --> <dependency> <groupId>mysql</groupId> <artifactId>mysql-connector-java</artifactId> <version>8.0.28</version> </dependency>
```

å› ä¸ºä¸æ˜¯å†…åµŒæ”¯æŒçš„ï¼Œæ‰€ä»¥éœ€è¦åŸºäºSinkFunctionè‡ªå®šä¹‰Sinkã€‚

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<String> text = env.fromElements( "Hello World", "Hello Flink", "Hello Java"); DataStream<Tuple2<String, Integer>> counts = text.flatMap(new Tokenizer()) .keyBy(value -> value.f0) .sum(1); // Transform the Tuple2<String, Integer> to a format acceptable by MySQL DataStream<String> mysqlData = counts.map(new MapFunction<Tuple2<String, Integer>, String>() { @Override public String map(Tuple2<String, Integer> value) throws Exception { return "'" + value.f0 + "'," + value.f1.toString(); } }); // Write the data stream to MySQL mysqlData.addSink(new MySqlSink()); env.execute("Word Count Example"); } public static class MySqlSink implements SinkFunction<String> { private Connection connection; private PreparedStatement preparedStatement; @Override public void invoke(String value, Context context) throws Exception { if(connection == null) { connection = DriverManager.getConnection("jdbc:mysql://localhost:3306/test", "username", "password"); preparedStatement = connection.prepareStatement("INSERT INTO my_table(word, count) VALUES("+ value +")"); } preparedStatement.executeUpdate(); } } }
```

### HBase Sink

éœ€è¦å¯¼å…¥HBaseçš„ä¾èµ–ï¼š

```xml
<!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-client --> <dependency> <groupId>org.apache.hbase</groupId> <artifactId>hbase-client</artifactId> <version>2.5.2</version> </dependency>
```

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<String> text = env.fromElements( "Hello World", "Hello Flink", "Hello Java"); DataStream<Tuple2<String, Integer>> counts = text.flatMap(new Tokenizer()) .keyBy(value -> value.f0) .sum(1); counts.addSink(new HBaseSink()); env.execute("Word Count Example"); } public static final class Tokenizer implements FlatMapFunction<String, Tuple2<String, Integer>> { @Override public void flatMap(String value, Collector<Tuple2<String, Integer>> out) { String[] words = value.toLowerCase().split("\\W+"); for (String word : words) { if (word.length() > 0) { out.collect(new Tuple2<>(word, 1)); } } } } public static class HBaseSink extends RichSinkFunction<Tuple2<String, Integer>> { private org.apache.hadoop.conf.Configuration config; private org.apache.hadoop.hbase.client.Connection connection; private Table table; @Override public void invoke(Tuple2<String, Integer> value, Context context) throws IOException { Put put = new Put(Bytes.toBytes(value.f0)); put.addColumn(Bytes.toBytes("cf"), Bytes.toBytes("count"), Bytes.toBytes(value.f1)); table.put(put); } @Override public void open(Configuration parameters) throws Exception { config = HBaseConfiguration.create(); config.set("hbase.zookeeper.quorum", "localhost"); config.set("hbase.zookeeper.property.clientPort", "2181"); connection = ConnectionFactory.createConnection(config); table = connection.getTable(TableName.valueOf("my-table")); } @Override public void close() throws Exception { table.close(); connection.close(); } }
```

`HBaseSink`ç±»æ˜¯`RichSinkFunction`çš„å®ç°ï¼Œç”¨äºå°†ç»“æœå†™å…¥HBaseæ•°æ®åº“ã€‚åœ¨`invoke`æ–¹æ³•ä¸­ï¼Œå®ƒå°†æ¥æ”¶åˆ°çš„æ¯ä¸ªäºŒå…ƒç»„ï¼ˆå•è¯å’Œè®¡æ•°ï¼‰å†™å…¥HBaseã€‚åœ¨`open`æ–¹æ³•ä¸­ï¼Œå®ƒåˆ›å»ºäº†ä¸HBaseçš„è¿æ¥ï¼Œå¹¶æŒ‡å®šäº†è¦å†™å…¥çš„è¡¨ã€‚åœ¨`close`æ–¹æ³•ä¸­ï¼Œå®ƒå…³é—­äº†ä¸HBaseçš„è¿æ¥å’Œè¡¨ã€‚

## åˆ†åŒºç­–ç•¥

åœ¨ Apache Flink ä¸­ï¼Œåˆ†åŒºï¼ˆPartitioningï¼‰æ˜¯å°†æ•°æ®æµæŒ‰ç…§ä¸€å®šçš„è§„åˆ™åˆ’åˆ†æˆå¤šä¸ªå­æ•°æ®æµæˆ–åˆ†ç‰‡ï¼Œä»¥ä¾¿åœ¨ä¸åŒçš„å¹¶è¡Œä»»åŠ¡æˆ–ç®—å­ä¸­å¹¶è¡Œå¤„ç†æ•°æ®ã€‚åˆ†åŒºæ˜¯å®ç°å¹¶è¡Œè®¡ç®—å’Œæ•°æ®æµå¤„ç†çš„åŸºç¡€æœºåˆ¶ã€‚Flink çš„åˆ†åŒºå†³å®šäº†æ•°æ®åœ¨ä½œä¸šä¸­çš„æµåŠ¨æ–¹å¼ï¼Œä»¥åŠåœ¨å¹¶è¡Œä»»åŠ¡ä¹‹é—´å¦‚ä½•åˆ†é…å’Œå¤„ç†æ•°æ®ã€‚

åœ¨ Flink ä¸­ï¼Œæ•°æ®æµå¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªæœ‰å‘å›¾ï¼Œå›¾ä¸­çš„èŠ‚ç‚¹ä»£è¡¨ç®—å­ï¼ˆOperatorsï¼‰ï¼Œè¾¹ä»£è¡¨æ•°æ®æµï¼ˆData Streamsï¼‰ã€‚æ•°æ®ä»æºç®—å­æµå‘ä¸‹æ¸¸ç®—å­ï¼Œè¿™äº›ç®—å­å¯èƒ½å¹¶è¡Œåœ°å¤„ç†è¾“å…¥æ•°æ®ï¼Œè€Œåˆ†åŒºå°±æ˜¯å†³å®šæ•°æ®å¦‚ä½•ä»ä¸€ä¸ªç®—å­ä¼ é€’åˆ°å¦ä¸€ä¸ªç®—å­çš„æœºåˆ¶ã€‚

ä¸‹é¢ä»‹ç»Flinkä¸­å¸¸ç”¨çš„å‡ ç§åˆ†åŒºç­–ç•¥ã€‚

### shuffle

åœºæ™¯ï¼šå¢å¤§åˆ†åŒºã€æé«˜å¹¶è¡Œåº¦ï¼Œè§£å†³æ•°æ®å€¾æ–œã€‚

DataStream â†’ DataStream

**åˆ†åŒºå…ƒç´ éšæœºå‡åŒ€åˆ†å‘åˆ°ä¸‹æ¸¸åˆ†åŒºï¼Œç½‘ç»œå¼€é”€æ¯”è¾ƒå¤§**

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Long> stream = env.fromSequence(1, 10).setParallelism(1); System.out.println(stream.getParallelism()); stream.shuffle().print(); env.execute(); }
```

è¾“å‡ºç»“æœï¼šä¸Šæ¸¸æ•°æ®æ¯”è¾ƒéšæ„åœ°åˆ†å‘åˆ°ä¸‹æ¸¸

```scala
1> 7 7> 1 2> 8 4> 5 8> 3 1> 9 8> 4 8> 10 6> 2 6> 6
```

### rebalance

åœºæ™¯ï¼šå¢å¤§åˆ†åŒºã€æé«˜å¹¶è¡Œåº¦ï¼Œè§£å†³æ•°æ®å€¾æ–œ

DataStream â†’ DataStream

**è½®è¯¢åˆ†åŒºå…ƒç´ ï¼Œå‡åŒ€çš„å°†å…ƒç´ åˆ†å‘åˆ°ä¸‹æ¸¸åˆ†åŒºï¼Œä¸‹æ¸¸æ¯ä¸ªåˆ†åŒºçš„æ•°æ®æ¯”è¾ƒå‡åŒ€ï¼Œåœ¨å‘ç”Ÿæ•°æ®å€¾æ–œæ—¶éå¸¸æœ‰ç”¨ï¼Œç½‘ç»œå¼€é”€æ¯”è¾ƒå¤§**

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Long> stream = env.fromSequence(1, 10).setParallelism(1); System.out.println(stream.getParallelism()); stream.rebalance().print(); env.execute(); }
```

è¾“å‡ºï¼šä¸Šæ¸¸æ•°æ®æ¯”è¾ƒå‡åŒ€çš„åˆ†å‘åˆ°ä¸‹æ¸¸

```scala
2> 2 1> 1 8> 8 5> 5 7> 7 4> 4 3> 3 6> 6 1> 9 2> 10
```

### rescale

åœºæ™¯ï¼šå‡å°‘åˆ†åŒºï¼Œé˜²æ­¢å‘ç”Ÿå¤§é‡çš„ç½‘ç»œä¼ è¾“ï¼Œä¸ä¼šå‘ç”Ÿå…¨é‡çš„é‡åˆ†åŒº

DataStream â†’ DataStream

é€šè¿‡è½®è¯¢åˆ†åŒºå…ƒç´ ï¼Œå°†ä¸€ä¸ªå…ƒç´ é›†åˆä»ä¸Šæ¸¸åˆ†åŒºå‘é€ç»™ä¸‹æ¸¸åˆ†åŒºï¼Œå‘é€å•ä½æ˜¯é›†åˆï¼Œè€Œä¸æ˜¯ä¸€ä¸ªä¸ªå…ƒç´ 

**å’Œå…¶ä»–é‡åˆ†åŒºç­–ç•¥ï¼ˆå¦‚ rebalanceã€forwardã€broadcast ç­‰ï¼‰ä¸åŒçš„æ˜¯ï¼Œrescale åœ¨è¿è¡Œæ—¶ä¸ä¼šæ”¹å˜å¹¶è¡Œåº¦ï¼Œè€Œä¸”å®ƒåªåœ¨æœ¬åœ°ï¼ˆåŒä¸€ä¸ª TaskManager å†…ï¼‰è¿›è¡Œæ•°æ®äº¤æ¢ï¼Œæ‰€ä»¥å®ƒæ¯”å…¶ä»–é‡åˆ†åŒºç­–ç•¥æ›´åŠ é«˜æ•ˆ**

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<String> dataStream = env.fromElements("1", "2", "3", "4", "5"); // ä½¿ç”¨MapFunctionå°†å…ƒç´ è½¬æ¢ä¸ºæ•´æ•°ç±»å‹ DataStream<Integer> intStream = dataStream.map(new MapFunction<String, Integer>() { @Override public Integer map(String value) { return Integer.parseInt(value); } }); // ä½¿ç”¨rescale()è¿›è¡Œé‡åˆ†åŒº DataStream<Integer> rescaledStream = intStream.rescale(); rescaledStream.print(); env.execute("Rescale Example"); }
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„DataStreamç„¶åé€šè¿‡`map()`å°†æ¯ä¸€ä¸ªå…ƒç´ è½¬æ¢ä¸ºæ•´æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯¹ç»“æœDataStreamåº”ç”¨`rescale()`æ“ä½œæ¥é‡åˆ†åŒºæ•°æ®ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ`rescale()`çš„å®é™…å½±å“å–å†³äºä½ çš„å¹¶è¡Œåº¦å’Œé›†ç¾¤ç¯å¢ƒï¼Œå¦‚æœä¸åŒçš„å¹¶è¡Œå®ä¾‹éƒ½åœ¨åŒä¸€å°æœºå™¨ä¸Šï¼Œæˆ–è€…å¹¶è¡Œåº¦åªæœ‰1ï¼Œé‚£ä¹ˆå¯èƒ½ä¸ä¼šçœ‹åˆ°`rescale()`çš„æ•ˆæœã€‚è€Œåœ¨å¤§è§„æ¨¡å¹¶è¡Œå¤„ç†çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨`rescale()`æ“ä½œå¯ä»¥æé«˜æ•°æ®å¤„ç†çš„æ•ˆç‡ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥åœ¨æ‰“å°ç»“æœä¸­çœ‹åˆ°`rescale`çš„å½±å“ï¼Œå› ä¸ºå®ƒæ”¹å˜çš„æ˜¯å†…éƒ¨æ•°æ®åˆ†å¸ƒå’Œå¤„ç†æ–¹å¼ï¼Œè€Œä¸æ˜¯è¾“å‡ºçš„ç»“æœã€‚å¦‚æœæƒ³è§‚å¯Ÿ`rescale`çš„ä½œç”¨ï¼Œéœ€è¦é€šè¿‡Flinkçš„Web UIæˆ–è€…æ—¥å¿—æ¥æŸ¥çœ‹ä»»åŠ¡æ‰§è¡Œæƒ…å†µï¼Œå¦‚æ•°æ®æµçš„åˆ†å¸ƒã€å„ä¸ªå­ä»»åŠ¡çš„è¿è¡ŒçŠ¶æ€ç­‰ä¿¡æ¯ã€‚

### broadcast

åœºæ™¯ï¼šéœ€è¦ä½¿ç”¨æ˜ å°„è¡¨ã€å¹¶ä¸”æ˜ å°„è¡¨ä¼šç»å¸¸å‘ç”Ÿå˜åŠ¨çš„åœºæ™¯

DataStream â†’ DataStream

ä¸Šæ¸¸ä¸­æ¯ä¸€ä¸ªå…ƒç´ å†…å®¹å¹¿æ’­åˆ°ä¸‹æ¸¸æ¯ä¸€ä¸ªåˆ†åŒºä¸­

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Integer> dataStream = env.fromElements(1, 2, 3, 4, 5); DataStream<String> broadcastStream = env.fromElements("2", "4"); MapStateDescriptor<String, String> descriptor = new MapStateDescriptor<>( "RulesBroadcastState", BasicTypeInfo.STRING_TYPE_INFO, BasicTypeInfo.STRING_TYPE_INFO); BroadcastStream<String> broadcastData = broadcastStream.broadcast(descriptor); dataStream.connect(broadcastData) .process(new BroadcastProcessFunction<Integer, String, String>() { @Override public void processElement(Integer value, ReadOnlyContext ctx, Collector<String> out) throws Exception { if (ctx.getBroadcastState(descriptor).contains(String.valueOf(value))) { out.collect("Value " + value + " matches with a broadcasted rule"); } } @Override public void processBroadcastElement(String rule, Context ctx, Collector<String> out) throws Exception { ctx.getBroadcastState(descriptor).put(rule, rule); } }).print(); env.execute("Broadcast State Example"); }
```

ä¸Šè¿°ä»£ç é¦–å…ˆå®šä¹‰äº†ä¸€ä¸ªä¸»æµå’Œä¸€ä¸ªè¦å¹¿æ’­çš„æµã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª`MapStateDescriptor`ï¼Œç”¨äºå­˜å‚¨å¹¿æ’­æ•°æ®ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†å¹¿æ’­æµè½¬æ¢ä¸º`BroadcastStream`ã€‚

æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨`connect()`æ–¹æ³•è¿æ¥ä¸»æµå’Œå¹¿æ’­æµï¼Œå¹¶æ‰§è¡Œ`process()`æ–¹æ³•ã€‚åœ¨è¿™ä¸ª`process()`æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸¤ä¸ªå¤„ç†å‡½æ•°ï¼š`processElement()`å’Œ`processBroadcastElement()`ã€‚`processElement()`ç”¨äºå¤„ç†ä¸»æµä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œå¹¶æ£€æŸ¥è¯¥å…ƒç´ æ˜¯å¦å­˜åœ¨äºå¹¿æ’­çŠ¶æ€ä¸­ã€‚å¦‚æœæ˜¯ï¼Œåˆ™è¾“å‡ºä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¡¨æ˜åŒ¹é…æˆåŠŸã€‚è€Œ`processBroadcastElement()`åˆ™ç”¨äºå¤„ç†å¹¿æ’­æµä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°å¹¿æ’­çŠ¶æ€ä¸­ã€‚

æ³¨æ„ï¼šåœ¨åˆ†å¸ƒå¼è®¡ç®—ç¯å¢ƒä¸­ï¼Œæ¯ä¸ªå¹¶è¡Œå®ä¾‹éƒ½ä¼šæ¥æ”¶å¹¿æ’­æµä¸­çš„æ‰€æœ‰å…ƒç´ ã€‚å› æ­¤ï¼Œå¹¿æ’­çŠ¶æ€å¯¹äºæ‰€æœ‰çš„å¹¶è¡Œå®ä¾‹éƒ½æ˜¯ä¸€æ ·çš„ã€‚ä¸è¿‡ï¼Œåœ¨Flink 1.13ç‰ˆæœ¬ä¸­ï¼Œå¹¿æ’­çŠ¶æ€å°šæœªåœ¨æ•…éšœæ¢å¤ä¸­æä¾›å®Œå…¨çš„ä¿éšœã€‚æ‰€ä»¥åœ¨äº‹ä»¶å‡ºç°æ•…éšœæ—¶ï¼Œå¹¿æ’­çŠ¶æ€å¯èƒ½ä¼šä¸¢å¤±æ•°æ®ã€‚

### global

åœºæ™¯ï¼šå¹¶è¡Œåº¦é™ä¸º1

DataStream â†’ DataStream

åœ¨ Apache Flink ä¸­ï¼ŒGlobal åˆ†åŒºç­–ç•¥æ„å‘³ç€æ‰€æœ‰æ•°æ®éƒ½è¢«å‘é€åˆ°ä¸‹æ¸¸ç®—å­çš„åŒä¸€ä¸ªåˆ†åŒºä¸­ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œä¸‹æ¸¸ç®—å­åªæœ‰ä¸€ä¸ªä»»åŠ¡å¤„ç†å…¨éƒ¨æ•°æ®ã€‚è¿™æ˜¯ä¸€ç§ç‰¹æ®Šçš„åˆ†åŒºç­–ç•¥ï¼Œåªæœ‰åœ¨ä¸‹æ¸¸ç®—å­èƒ½å¤Ÿå¾ˆå¿«åœ°å¤„ç†æ‰€æœ‰æ•°æ®ï¼Œæˆ–è€…éœ€è¦å…¨å±€æ’åºæˆ–å…¨å±€èšåˆæ—¶æ‰ä¼šä½¿ç”¨ã€‚

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // åˆ›å»ºä¸€ä¸ªä»1åˆ°100çš„æ•°å­—æµ DataStream<Long> numberStream = env.fromSequence(1, 100); // å¯¹æµåº”ç”¨ map function DataStream<Long> result = numberStream.global() .map(new MapFunction<Long, Long>() { @Override public Long map(Long value) { System.out.println("Processing " + value); return value * 2; } }); result.print(); env.execute("Global Partition Example"); }
```

ä»¥ä¸Šä»£ç åˆ›å»ºäº†ä¸€ä¸ªé¡ºåºç”Ÿæˆ 1-100 çš„æ•°å­—æµï¼Œå¹¶åº”ç”¨äº† Global Partitionï¼Œç„¶åå¯¹æ¯ä¸ªæ•°å­—è¿›è¡Œä¹˜2çš„æ“ä½œã€‚å®é™…è¿è¡Œæ­¤ä»£ç æ—¶ï¼Œä½ ä¼šè§‚å¯Ÿåˆ°æ‰€æœ‰çš„æ•°å­—éƒ½ç”±åŒä¸€ä»»åŠ¡å¤„ç†ï¼Œæ‰“å°å‡ºæ¥çš„å¤„ç†é¡ºåºæ˜¯è¿ç»­çš„ã€‚è¿™å°±æ˜¯ Global Partition çš„ä½œç”¨ï¼šæ‰€æœ‰æ•°æ®éƒ½è¢«å‘é€åˆ°ä¸‹æ¸¸ç®—å­çš„åŒä¸€å®ä¾‹è¿›è¡Œå¤„ç†ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ­¤ç¤ºä¾‹åªæ˜¯ä¸ºäº†æ¼”ç¤º Global Partition çš„å·¥ä½œåŸç†ï¼Œå®é™…ä¸Šå¹¶ä¸æ¨èåœ¨è´Ÿè½½å‡è¡¡å¾ˆé‡è¦çš„åº”ç”¨åœºæ™¯ä¸­ä½¿ç”¨è¿™ç§åˆ†åŒºç­–ç•¥ï¼Œå› ä¸ºå®ƒå¯èƒ½å¯¼è‡´ä¸¥é‡çš„æ€§èƒ½é—®é¢˜ã€‚

### forward

åœºæ™¯ï¼šä¸€å¯¹ä¸€çš„æ•°æ®åˆ†å‘,é»˜è®¤çš„åˆ†åŒºç­–ç•¥ï¼Œæ•°æ®åœ¨å„ä¸ªç®—å­ä¹‹é—´ä¸ä¼šé‡æ–°åˆ†é…ã€‚mapã€flatMapã€filter ç­‰éƒ½æ˜¯è¿™ç§åˆ†åŒºç­–ç•¥

DataStream â†’ DataStream

ä¸Šæ¸¸åˆ†åŒºæ•°æ®åˆ†å‘åˆ°ä¸‹æ¸¸å¯¹åº”åˆ†åŒºä¸­

partition1->partition1ï¼›partition2->partition2

æ³¨æ„ï¼šå¿…é¡»ä¿è¯ä¸Šä¸‹æ¸¸åˆ†åŒºæ•°ï¼ˆå¹¶è¡Œåº¦ï¼‰ä¸€è‡´ï¼Œä¸ç„¶ä¼šæœ‰å¦‚ä¸‹å¼‚å¸¸:

```scala
Forward partitioning does not allow change of parallelism. Upstream operation: Source: Socket Stream-1 parallelism: 1, downstream operation: Map-3 parallelism: 8 You must use another partitioning strategy, such as broadcast, rebalance, shuffle or global.
```

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Integer> dataStream = env.fromElements(1, 2, 3, 4, 5, 6, 7, 8, 9, 10).setParallelism(1); DataStream<Integer> forwardStream = dataStream.forward().map(new MapFunction<Integer, Integer>() { @Override public Integer map(Integer value) throws Exception { return value * value; } }).setParallelism(1); forwardStream.print(); env.execute("Flink Forward Example"); }
```

æ­¤ä»£ç é¦–å…ˆåˆ›å»ºä¸€ä¸ªä»1åˆ°10çš„æ•°æ®æµã€‚ç„¶åï¼Œå®ƒä½¿ç”¨ Forward ç­–ç•¥å°†è¿™ä¸ªæ•°æ®æµé€å…¥ä¸€ä¸ª MapFunction ä¸­ï¼Œè¯¥å‡½æ•°å°†æ¯ä¸ªæ•°å­—å¹³æ–¹ã€‚ç„¶åï¼Œå®ƒæ‰“å°å‡ºç»“æœã€‚æ³¨æ„ï¼šä»¥ä¸Šä»£ç ä¸­çš„forwardè°ƒç”¨å®é™…ä¸Šå¹¶æ²¡æœ‰æ”¹å˜ä»»ä½•åˆ†åŒºç­–ç•¥ï¼Œå› ä¸ºforwardæ˜¯é»˜è®¤åˆ†åŒºç­–ç•¥ã€‚è¿™é‡Œæ·»åŠ forwardè°ƒç”¨ä¸»è¦æ˜¯ä¸ºäº†è¯´æ˜å…¶å­˜åœ¨å’Œä½¿ç”¨æ–¹æ³•ã€‚

### keyBy

åœºæ™¯ï¼šä¸ä¸šåŠ¡åœºæ™¯åŒ¹é…

DataStream â†’ DataStream

æ ¹æ®ä¸Šæ¸¸åˆ†åŒºå…ƒç´ çš„Hashå€¼ä¸ä¸‹æ¸¸åˆ†åŒºæ•°å–æ¨¡è®¡ç®—å‡ºï¼Œå°†å½“å‰å…ƒç´ åˆ†å‘åˆ°ä¸‹æ¸¸å“ªä¸€ä¸ªåˆ†åŒº

```scala
MathUtils.murmurHash(keyHash)ï¼ˆæ¯ä¸ªå…ƒç´ çš„Hashå€¼ï¼‰ % maxParallelismï¼ˆä¸‹æ¸¸åˆ†åŒºæ•°ï¼‰
```

```java
public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Tuple2<Integer, Integer>> dataStream = env.fromElements( new Tuple2<>(1, 3), new Tuple2<>(1, 5), new Tuple2<>(2, 4), new Tuple2<>(2, 6), new Tuple2<>(3, 7) ); // ä½¿ç”¨ keyBy å¯¹æµè¿›è¡Œåˆ†åŒºæ“ä½œ DataStream<Tuple2<Integer, Integer>> keyedStream = dataStream .keyBy(0) // æ ¹æ®å…ƒç»„çš„ç¬¬ä¸€ä¸ªå­—æ®µè¿›è¡Œåˆ†åŒº .sum(1); // å¯¹æ¯ä¸ªé”®å¯¹åº”çš„ç¬¬äºŒä¸ªå­—æ®µæ±‚å’Œ keyedStream.print(); env.execute("KeyBy example"); }
```

ä»¥ä¸Šç¨‹åºé¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ªåŒ…å«äº”ä¸ªå…ƒç»„çš„æµï¼Œç„¶åä½¿ç”¨ `keyBy` æ–¹æ³•æ ¹æ®å…ƒç»„çš„ç¬¬ä¸€ä¸ªå­—æ®µè¿›è¡Œåˆ†åŒºï¼Œå¹¶å¯¹æ¯ä¸ªé”®å¯¹åº”çš„ç¬¬äºŒä¸ªå­—æ®µæ±‚å’Œã€‚æ‰§è¡Œç»“æœä¸­ï¼Œæ¯ä¸ªé”®çš„å€¼é›†åˆéƒ½è¢«æ˜ å°„æˆäº†ä¸€ä¸ªæ–°çš„å…ƒç»„ï¼Œå…¶ç¬¬ä¸€ä¸ªå­—æ®µæ˜¯é”®ï¼Œç¬¬äºŒä¸ªå­—æ®µæ˜¯ç›¸åº”çš„å’Œã€‚

æ³¨æ„ï¼šåœ¨ä»¥ä¸Šä»£ç ä¸­ï¼Œ`keyBy(0)` è¡¨ç¤ºæ ¹æ®å…ƒç»„çš„ç¬¬ä¸€ä¸ªå­—æ®µï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼‰è¿›è¡Œåˆ†åŒºæ“ä½œã€‚å¦å¤–ï¼Œæ— è®ºä»€ä¹ˆæƒ…å†µï¼Œéƒ½éœ€è¦ç¡®ä¿ä½ çš„ Flink é›†ç¾¤æ˜¯æ­£å¸¸è¿è¡Œçš„ï¼Œå¦åˆ™ç¨‹åºå¯èƒ½æ— æ³•æ‰§è¡ŒæˆåŠŸã€‚

### PartitionCustom

DataStream â†’ DataStream

é€šè¿‡è‡ªå®šä¹‰çš„åˆ†åŒºå™¨ï¼Œæ¥å†³å®šå…ƒç´ æ˜¯å¦‚ä½•ä»ä¸Šæ¸¸åˆ†åŒºåˆ†å‘åˆ°ä¸‹æ¸¸åˆ†åŒº

```java
public static void main(String[] args) throws Exception { final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); DataStream<Integer> data = env.fromElements(1,2,3,4,5,6,7,8,9,10); // ä½¿ç”¨è‡ªå®šä¹‰åˆ†åŒºå™¨è¿›è¡Œåˆ†åŒº data.partitionCustom(new MyPartitioner(), i -> i).print(); env.execute("Custom partition example"); } public static class MyPartitioner implements Partitioner<Integer> { @Override public int partition(Integer key, int numPartitions) { return key % numPartitions; } }
```

è¿™ä¸ªç¨‹åºå°†åˆ›å»ºä¸€ä¸ªæ•°æ®æµï¼Œå…¶ä¸­åŒ…å«ä»1åˆ°10çš„æ•´æ•°ã€‚ç„¶åï¼Œå®ƒä½¿ç”¨äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„åˆ†åŒºå™¨`MyPartitioner`æ¥å¯¹è¿™ä¸ªæ•°æ®æµè¿›è¡Œåˆ†åŒºã€‚è¿™ä¸ªåˆ†åŒºå™¨æ ¹æ®å…ƒç´ çš„å€¼å¯¹`numPartitions`å–æ¨¡æ¥å†³å®šæ•°æ®å»åˆ°å“ªä¸ªåˆ†åŒºã€‚

ç”±äºç¯‡å¹…é™åˆ¶ï¼Œæˆ‘ä»¬å°†åœ¨æ­¤ç»“æŸæœ¬ç¯‡å†…å®¹ã€‚ç¨å¾®æ•´ç†ä¸€ä¸‹ï¼Œä¸‹ç¯‡é©¬ä¸Šå‘ã€‚

å¸Œæœ›è¿™ç¯‡æ–‡ç« èƒ½å¤Ÿç»™ä½ å¸¦æ¥æ”¶è·å’Œæ€è€ƒï¼Œå¦‚æœæœ‰æ”¶è·ï¼Œå¸Œæœ›èƒ½ä¸åç‚¹ä¸ªèµæˆ–è€…å†çœ‹ï¼Œè°¢è°¢ã€‚